{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvMbpqbGgHVCm3jmrNbFjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingruiWang/RUC-Deep-Learning-Course/blob/master/Homework/HW_4/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAD79lKDIVQw"
      },
      "source": [
        "# Homework 4: Comparation Between Different Optimazors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XsH6fC-Hv0I",
        "outputId": "4deb8988-36b8-4bec-a333-9cccc6cb790c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive/RUC/DeepLearning/course7\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/RUC/DeepLearning/course7\n",
            "data_facescore\tdata_foodscore\tFoodScore.csv  程序\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDZrYqTbIJ2R"
      },
      "source": [
        "### 1. Loading required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAmj28XAH8wD"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import Model, Input\n",
        "from keras.layers import Dense,Flatten,Input\n",
        "from keras.optimizers import SGD,RMSprop,Adam\n",
        "\n",
        "from keras.utils import to_categorical "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8LDwgj5IvkF",
        "outputId": "964686d2-788a-47bb-e72b-2e188267f153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "## loading mnist dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
        "\n",
        "## One-hot encode y label\n",
        "Y_train=to_categorical(y_train)\n",
        "Y_test=to_categorical(y_test)\n",
        "\n",
        "print(Y_train.shape) # 60000 * 10. 60000 means the amount of data, 10 means 10 classes of number in dataset.\n",
        "print(Y_train[0]) # [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] means number 5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 10)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYlRvV9cKKDl"
      },
      "source": [
        "### Model by Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vALzfTkqNBML"
      },
      "source": [
        "Model structure: a two-layer neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t01y8pDKF0N"
      },
      "source": [
        "def NNModel(IMSIZE = 28, p = 1000, q = 10):  \n",
        "    '''\n",
        "    Define the model\n",
        "    Parameter:\n",
        "        IMSIZE: the size of input image, the width and height are same here.\n",
        "        p: the number of neuron in first hidden layer, defult value is 1000\n",
        "        q: the number of neuron in output layer，defult value is 10 since there are 10 classes.\n",
        "    return:\n",
        "        model: the keras model\n",
        "    '''                                            \n",
        "    input_layer = Input([IMSIZE,IMSIZE])       # MNIST图像为28*28的单层图片\n",
        "    x = input_layer                              \n",
        "    x = Flatten()(input_layer)                   # 将28*28*1的Tensor拉直为784维向量\n",
        "    x = Dense(1000,activation = 'relu')(x)       # 全连接到1000个节点，并采用relu激活函数\n",
        "    x = Dense(10,activation = 'softmax')(x)      # 全连接到10个节点，并采用softmax激活函数转化为(0,1)取值\n",
        "    output_layer=x\n",
        "    model=Model(input_layer,output_layer)    # Model函数将input_layer 和 output_layer中间的部分连接起来\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y_0_8g6WVCi"
      },
      "source": [
        "def Momentum(lr, momentum = 0.5):\n",
        "    return SGD(lr = lr, momentum = momentum)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8gjIf9QATK"
      },
      "source": [
        "def train(model, X_train, X_test, y_train, y_test,\n",
        "            batch_size = 128, epochs = 50,\n",
        "            opt = SGD, lr = 0.001, \n",
        "            loss_type = \"categorical_crossentropy\",\n",
        "            metrics = ['accuracy']):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    model.compile(loss = loss_type, optimizer = opt(lr = lr), metrics = metrics)\n",
        "    history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size = batch_size, epochs = epochs, verbose = 0)\n",
        "    train_loss = history.history[\"loss\"]\n",
        "\n",
        "    return model, train_loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJWwcbWISCnk"
      },
      "source": [
        "def render_loss(losses, name):\n",
        "    t = np.arange(len(losses[0]))\n",
        "    for i, loss in enumerate(losses):\n",
        "        print(i, loss)\n",
        "        plt.plot(t, loss, label = name[i])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('loss') \n",
        "    plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0faVky43T0QI",
        "outputId": "d699c513-2a3e-4e62-8a35-f39dfa85c91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimizors = [\"SGD\", \"Momentum\", \"RMSprop\", \"Adam\"]\n",
        "losses = [None] * 4\n",
        "\n",
        "for i, opt in enumerate(optimizors):\n",
        "    print(\"Training %s \"%(opt))\n",
        "    model = NNModel()\n",
        "    model, loss = train(model,  X_train, X_test, Y_train, Y_test, opt = eval(optimizors[i]))\n",
        "    losses[i] = loss"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SGD \n",
            "Model: \"functional_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 5.0087 - accuracy: 0.9035 - val_loss: 0.9665 - val_accuracy: 0.9358\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5301 - accuracy: 0.9558 - val_loss: 0.7132 - val_accuracy: 0.9475\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2456 - accuracy: 0.9719 - val_loss: 0.6177 - val_accuracy: 0.9490\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1264 - accuracy: 0.9806 - val_loss: 0.5778 - val_accuracy: 0.9533\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9878 - val_loss: 0.5996 - val_accuracy: 0.9504\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0322 - accuracy: 0.9927 - val_loss: 0.5533 - val_accuracy: 0.9546\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.5253 - val_accuracy: 0.9555\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.5314 - val_accuracy: 0.9571\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5277 - val_accuracy: 0.9571\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5242 - val_accuracy: 0.9572\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 9.5846e-04 - accuracy: 0.9999 - val_loss: 0.5253 - val_accuracy: 0.9562\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 6.1691e-04 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9569\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.9975e-04 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.9569\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.3909e-04 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9574\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.9965e-04 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.9576\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.7070e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9578\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4245e-04 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.9579\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.2314e-04 - accuracy: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.9578\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.0378e-04 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9580\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.8777e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9579\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.7539e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9579\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.6219e-04 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9579\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.5202e-04 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.9583\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.4165e-04 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.9583\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3301e-04 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.9584\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.2472e-04 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9584\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.1729e-04 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9577\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.1038e-04 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9582\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.0383e-04 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.9582\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9794e-04 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9578\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9227e-04 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.9580\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8702e-04 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.9582\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8229e-04 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.9582\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7737e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9582\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7320e-04 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.9584\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6927e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9582\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6528e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9582\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6172e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9582\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5804e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9582\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5479e-04 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9582\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5176e-04 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9583\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4862e-04 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9581\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4585e-04 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.9581\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4303e-04 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9583\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4037e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9583\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3785e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9584\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3530e-04 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9585\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3302e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9586\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3072e-04 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.9587\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.2855e-04 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.9586\n",
            "Training Momentum \n",
            "Model: \"functional_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.6659 - accuracy: 0.8967 - val_loss: 0.4926 - val_accuracy: 0.9302\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.9518 - val_loss: 0.3660 - val_accuracy: 0.9418\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1302 - accuracy: 0.9702 - val_loss: 0.3363 - val_accuracy: 0.9483\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9807 - val_loss: 0.3190 - val_accuracy: 0.9513\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9879 - val_loss: 0.3126 - val_accuracy: 0.9529\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.9925 - val_loss: 0.3078 - val_accuracy: 0.9546\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.3098 - val_accuracy: 0.9539\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.3008 - val_accuracy: 0.9562\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.3032 - val_accuracy: 0.9566\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.3045 - val_accuracy: 0.9561\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.3044 - val_accuracy: 0.9581\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.3063 - val_accuracy: 0.9569\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.3057 - val_accuracy: 0.9576\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.3064 - val_accuracy: 0.9580\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.3053 - val_accuracy: 0.9589\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.3064 - val_accuracy: 0.9595\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.3071 - val_accuracy: 0.9592\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.3064 - val_accuracy: 0.9599\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.3071 - val_accuracy: 0.9598\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.3079 - val_accuracy: 0.9601\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.3083 - val_accuracy: 0.9599\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.3091 - val_accuracy: 0.9597\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.3092 - val_accuracy: 0.9596\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.3088 - val_accuracy: 0.9601\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.3101 - val_accuracy: 0.9600\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.3110 - val_accuracy: 0.9602\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.3110 - val_accuracy: 0.9604\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.3120 - val_accuracy: 0.9602\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.3113 - val_accuracy: 0.9605\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.3123 - val_accuracy: 0.9602\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.3123 - val_accuracy: 0.9607\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.3130 - val_accuracy: 0.9603\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.3129 - val_accuracy: 0.9605\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.3137 - val_accuracy: 0.9603\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.3142 - val_accuracy: 0.9608\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.3143 - val_accuracy: 0.9604\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.3148 - val_accuracy: 0.9609\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.3147 - val_accuracy: 0.9607\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.3155 - val_accuracy: 0.9608\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.3151 - val_accuracy: 0.9611\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.3158 - val_accuracy: 0.9604\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.3162 - val_accuracy: 0.9607\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.3169 - val_accuracy: 0.9610\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 9.7057e-04 - accuracy: 0.9999 - val_loss: 0.3171 - val_accuracy: 0.9612\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 9.3700e-04 - accuracy: 0.9999 - val_loss: 0.3171 - val_accuracy: 0.9612\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 9.0951e-04 - accuracy: 0.9999 - val_loss: 0.3170 - val_accuracy: 0.9615\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.8149e-04 - accuracy: 0.9999 - val_loss: 0.3176 - val_accuracy: 0.9619\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.5411e-04 - accuracy: 0.9999 - val_loss: 0.3181 - val_accuracy: 0.9615\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.3414e-04 - accuracy: 0.9999 - val_loss: 0.3180 - val_accuracy: 0.9614\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1009e-04 - accuracy: 0.9999 - val_loss: 0.3184 - val_accuracy: 0.9616\n",
            "Training RMSprop \n",
            "Model: \"functional_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 5.7439 - accuracy: 0.9081 - val_loss: 0.7848 - val_accuracy: 0.9504\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7156 - accuracy: 0.9565 - val_loss: 0.6154 - val_accuracy: 0.9642\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5295 - accuracy: 0.9680 - val_loss: 0.8455 - val_accuracy: 0.9556\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3953 - accuracy: 0.9746 - val_loss: 0.7260 - val_accuracy: 0.9661\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3552 - accuracy: 0.9780 - val_loss: 0.7788 - val_accuracy: 0.9699\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3292 - accuracy: 0.9804 - val_loss: 0.7464 - val_accuracy: 0.9722\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2736 - accuracy: 0.9836 - val_loss: 0.7552 - val_accuracy: 0.9727\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2552 - accuracy: 0.9853 - val_loss: 1.0102 - val_accuracy: 0.9647\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2448 - accuracy: 0.9862 - val_loss: 0.8340 - val_accuracy: 0.9716\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2051 - accuracy: 0.9884 - val_loss: 0.8671 - val_accuracy: 0.9731\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2169 - accuracy: 0.9887 - val_loss: 0.8516 - val_accuracy: 0.9755\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1968 - accuracy: 0.9901 - val_loss: 0.9998 - val_accuracy: 0.9730\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1947 - accuracy: 0.9902 - val_loss: 0.9793 - val_accuracy: 0.9746\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1579 - accuracy: 0.9920 - val_loss: 1.0060 - val_accuracy: 0.9722\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1573 - accuracy: 0.9922 - val_loss: 0.9705 - val_accuracy: 0.9741\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1382 - accuracy: 0.9928 - val_loss: 1.0440 - val_accuracy: 0.9752\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1842 - accuracy: 0.9925 - val_loss: 1.1237 - val_accuracy: 0.9740\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1522 - accuracy: 0.9933 - val_loss: 1.1235 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1254 - accuracy: 0.9938 - val_loss: 0.9647 - val_accuracy: 0.9774\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1308 - accuracy: 0.9941 - val_loss: 1.0752 - val_accuracy: 0.9764\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1323 - accuracy: 0.9936 - val_loss: 1.1929 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1219 - accuracy: 0.9944 - val_loss: 1.1013 - val_accuracy: 0.9785\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1139 - accuracy: 0.9949 - val_loss: 1.1207 - val_accuracy: 0.9798\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1004 - accuracy: 0.9952 - val_loss: 1.1729 - val_accuracy: 0.9765\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1142 - accuracy: 0.9947 - val_loss: 1.2861 - val_accuracy: 0.9764\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0971 - accuracy: 0.9953 - val_loss: 1.3488 - val_accuracy: 0.9761\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9953 - val_loss: 1.5768 - val_accuracy: 0.9743\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0920 - accuracy: 0.9960 - val_loss: 1.4112 - val_accuracy: 0.9757\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9955 - val_loss: 1.3387 - val_accuracy: 0.9796\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0904 - accuracy: 0.9962 - val_loss: 1.4655 - val_accuracy: 0.9754\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0971 - accuracy: 0.9957 - val_loss: 1.3878 - val_accuracy: 0.9797\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0870 - accuracy: 0.9967 - val_loss: 1.2987 - val_accuracy: 0.9795\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9970 - val_loss: 1.2333 - val_accuracy: 0.9811\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0760 - accuracy: 0.9968 - val_loss: 1.6663 - val_accuracy: 0.9783\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0783 - accuracy: 0.9965 - val_loss: 1.4560 - val_accuracy: 0.9810\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0692 - accuracy: 0.9970 - val_loss: 1.4682 - val_accuracy: 0.9798\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0883 - accuracy: 0.9965 - val_loss: 1.3415 - val_accuracy: 0.9812\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0826 - accuracy: 0.9970 - val_loss: 1.3141 - val_accuracy: 0.9829\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0696 - accuracy: 0.9973 - val_loss: 1.5314 - val_accuracy: 0.9798\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0714 - accuracy: 0.9971 - val_loss: 1.5051 - val_accuracy: 0.9800\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0547 - accuracy: 0.9977 - val_loss: 1.5376 - val_accuracy: 0.9787\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0561 - accuracy: 0.9977 - val_loss: 1.6046 - val_accuracy: 0.9790\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0734 - accuracy: 0.9972 - val_loss: 1.4681 - val_accuracy: 0.9787\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0612 - accuracy: 0.9976 - val_loss: 1.3744 - val_accuracy: 0.9824\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.9978 - val_loss: 1.5038 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9981 - val_loss: 1.4391 - val_accuracy: 0.9815\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0610 - accuracy: 0.9976 - val_loss: 1.4569 - val_accuracy: 0.9808\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9979 - val_loss: 1.4719 - val_accuracy: 0.9820\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0657 - accuracy: 0.9977 - val_loss: 1.6173 - val_accuracy: 0.9783\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.9978 - val_loss: 1.4605 - val_accuracy: 0.9820\n",
            "Training Adam \n",
            "Model: \"functional_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 4.4984 - accuracy: 0.9150 - val_loss: 0.7636 - val_accuracy: 0.9480\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4242 - accuracy: 0.9615 - val_loss: 0.5333 - val_accuracy: 0.9538\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9708 - val_loss: 0.4646 - val_accuracy: 0.9609\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1847 - accuracy: 0.9756 - val_loss: 0.6192 - val_accuracy: 0.9530\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2404 - accuracy: 0.9724 - val_loss: 0.5460 - val_accuracy: 0.9569\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1909 - accuracy: 0.9762 - val_loss: 0.4021 - val_accuracy: 0.9626\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1989 - accuracy: 0.9768 - val_loss: 0.4293 - val_accuracy: 0.9597\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9773 - val_loss: 0.4168 - val_accuracy: 0.9638\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1946 - accuracy: 0.9767 - val_loss: 0.4652 - val_accuracy: 0.9624\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2114 - accuracy: 0.9771 - val_loss: 0.4980 - val_accuracy: 0.9638\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1964 - accuracy: 0.9786 - val_loss: 0.5074 - val_accuracy: 0.9618\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1970 - accuracy: 0.9803 - val_loss: 0.5548 - val_accuracy: 0.9649\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1712 - accuracy: 0.9818 - val_loss: 0.5167 - val_accuracy: 0.9665\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9825 - val_loss: 0.5152 - val_accuracy: 0.9670\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1643 - accuracy: 0.9830 - val_loss: 0.4591 - val_accuracy: 0.9683\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1663 - accuracy: 0.9833 - val_loss: 0.5829 - val_accuracy: 0.9678\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1413 - accuracy: 0.9854 - val_loss: 0.5612 - val_accuracy: 0.9675\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1543 - accuracy: 0.9856 - val_loss: 0.6059 - val_accuracy: 0.9701\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1314 - accuracy: 0.9873 - val_loss: 0.6444 - val_accuracy: 0.9703\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1405 - accuracy: 0.9874 - val_loss: 0.6433 - val_accuracy: 0.9703\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1245 - accuracy: 0.9883 - val_loss: 0.7160 - val_accuracy: 0.9676\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1270 - accuracy: 0.9881 - val_loss: 0.5920 - val_accuracy: 0.9735\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9886 - val_loss: 0.7056 - val_accuracy: 0.9721\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1356 - accuracy: 0.9884 - val_loss: 0.8493 - val_accuracy: 0.9714\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1394 - accuracy: 0.9888 - val_loss: 0.8875 - val_accuracy: 0.9679\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9907 - val_loss: 0.7674 - val_accuracy: 0.9735\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1399 - accuracy: 0.9901 - val_loss: 0.9747 - val_accuracy: 0.9704\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9903 - val_loss: 0.9720 - val_accuracy: 0.9736\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1245 - accuracy: 0.9912 - val_loss: 0.9341 - val_accuracy: 0.9716\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.9931 - val_loss: 1.1080 - val_accuracy: 0.9722\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1147 - accuracy: 0.9922 - val_loss: 0.9673 - val_accuracy: 0.9747\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1200 - accuracy: 0.9925 - val_loss: 1.0651 - val_accuracy: 0.9721\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1310 - accuracy: 0.9916 - val_loss: 1.1085 - val_accuracy: 0.9763\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1064 - accuracy: 0.9934 - val_loss: 1.2361 - val_accuracy: 0.9729\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.9938 - val_loss: 1.1504 - val_accuracy: 0.9750\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1299 - accuracy: 0.9926 - val_loss: 1.3018 - val_accuracy: 0.9718\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0991 - accuracy: 0.9937 - val_loss: 1.1615 - val_accuracy: 0.9748\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9946 - val_loss: 1.2323 - val_accuracy: 0.9758\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1381 - accuracy: 0.9934 - val_loss: 1.8263 - val_accuracy: 0.9712\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1512 - accuracy: 0.9930 - val_loss: 1.3571 - val_accuracy: 0.9742\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1044 - accuracy: 0.9944 - val_loss: 1.4632 - val_accuracy: 0.9737\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9943 - val_loss: 1.4536 - val_accuracy: 0.9742\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0784 - accuracy: 0.9955 - val_loss: 1.4730 - val_accuracy: 0.9725\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1052 - accuracy: 0.9948 - val_loss: 1.4657 - val_accuracy: 0.9747\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1300 - accuracy: 0.9944 - val_loss: 1.6190 - val_accuracy: 0.9729\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1169 - accuracy: 0.9945 - val_loss: 1.5770 - val_accuracy: 0.9769\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9954 - val_loss: 1.5811 - val_accuracy: 0.9770\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9963 - val_loss: 1.5511 - val_accuracy: 0.9744\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9958 - val_loss: 1.5873 - val_accuracy: 0.9776\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0948 - accuracy: 0.9954 - val_loss: 1.6040 - val_accuracy: 0.9758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Cg5CRbXBAd",
        "outputId": "29714f78-37c8-4393-95f1-4556c35cc23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "render_loss(losses, optimizors)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [26.877620697021484, 2.156327247619629, 1.456807255744934, 1.1061608791351318, 0.8865046501159668, 0.7309371829032898, 0.6171231865882874, 0.5255106091499329, 0.4502044916152954, 0.3884611427783966, 0.33812326192855835, 0.2956332862377167, 0.25858139991760254, 0.22698642313480377, 0.19987766444683075, 0.1745505928993225, 0.15369459986686707, 0.1358175128698349, 0.119856096804142, 0.10546425729990005, 0.09342805296182632, 0.08293431252241135, 0.07369124889373779, 0.06504761427640915, 0.05765078216791153, 0.050966303795576096, 0.04498959332704544, 0.04000958800315857, 0.03565880283713341, 0.03134467452764511, 0.027850441634655, 0.02486211620271206, 0.021916981786489487, 0.01960454322397709, 0.017485063523054123, 0.015754230320453644, 0.014067051000893116, 0.012692403048276901, 0.011423476040363312, 0.010249331593513489, 0.009291143156588078, 0.00833122618496418, 0.007513092365115881, 0.006880597211420536, 0.006255702581256628, 0.005704211536794901, 0.00522809661924839, 0.004776145797222853, 0.004352794960141182, 0.00400103535503149]\n",
            "1 [35.2614631652832, 1.0316559076309204, 0.7099465727806091, 0.5472647547721863, 0.442971795797348, 0.36937204003334045, 0.3147594630718231, 0.2709614634513855, 0.23581728339195251, 0.20717403292655945, 0.18329782783985138, 0.16259713470935822, 0.14563339948654175, 0.13046897947788239, 0.11669639497995377, 0.10525646805763245, 0.09513915330171585, 0.08671077340841293, 0.07899942994117737, 0.07250764966011047, 0.0661754161119461, 0.06085415557026863, 0.05601556971669197, 0.05166838318109512, 0.047819092869758606, 0.0444989949464798, 0.04129192978143692, 0.038502778857946396, 0.0359848290681839, 0.033680349588394165, 0.03165024146437645, 0.029672682285308838, 0.02792959474027157, 0.026337115094065666, 0.024896295741200447, 0.023535536602139473, 0.022346127778291702, 0.02121530845761299, 0.02013479731976986, 0.019193492829799652, 0.018285030499100685, 0.017457837238907814, 0.01672070100903511, 0.01594809629023075, 0.015351232141256332, 0.014743645675480366, 0.014149900525808334, 0.013651442714035511, 0.01312930416315794, 0.012652365490794182]\n",
            "2 [36.62194061279297, 2.929091215133667, 1.1322507858276367, 0.4822712242603302, 0.3057546019554138, 0.25910046696662903, 0.20435656607151031, 0.17593863606452942, 0.14608170092105865, 0.16431450843811035, 0.13557054102420807, 0.12032107263803482, 0.09436676651239395, 0.10355457663536072, 0.09741472452878952, 0.08488765358924866, 0.08714453876018524, 0.06818195432424545, 0.08011354506015778, 0.08849214017391205, 0.0864042416214943, 0.056242357939481735, 0.07737337797880173, 0.05644019693136215, 0.07513163238763809, 0.06062021106481552, 0.06991903483867645, 0.05808667838573456, 0.05565753951668739, 0.05320717766880989, 0.05752745270729065, 0.0527576245367527, 0.0487765297293663, 0.04771459847688675, 0.05219702422618866, 0.04631034657359123, 0.04347929358482361, 0.05093960464000702, 0.056800421327352524, 0.03713694587349892, 0.045722879469394684, 0.03777836263179779, 0.042742401361465454, 0.04055489972233772, 0.0431150458753109, 0.03880278021097183, 0.035507284104824066, 0.04879479482769966, 0.03078911267220974, 0.03670167177915573]\n",
            "3 [21.393993377685547, 1.9669692516326904, 0.8614022135734558, 0.4809831380844116, 0.26115813851356506, 0.1852247416973114, 0.12690110504627228, 0.0684920996427536, 0.043818917125463486, 0.034631408751010895, 0.021854771301150322, 0.012229801155626774, 0.009999401867389679, 0.015964802354574203, 0.023870164528489113, 0.024827394634485245, 0.048525720834732056, 0.044299036264419556, 0.04195380210876465, 0.03056350350379944, 0.027156762778759003, 0.01993500255048275, 0.01568553037941456, 0.02179006114602089, 0.023686828091740608, 0.022044364362955093, 0.03386649489402771, 0.037695806473493576, 0.032706912606954575, 0.03969203308224678, 0.03537752106785774, 0.03775760158896446, 0.03329601138830185, 0.03907044976949692, 0.04064645245671272, 0.030931919813156128, 0.03983451426029205, 0.03508593887090683, 0.03267672285437584, 0.031739458441734314, 0.03213196620345116, 0.02799815684556961, 0.03225264325737953, 0.03753078728914261, 0.042652677744627, 0.034087274223566055, 0.052902378141880035, 0.04541768878698349, 0.03604019433259964, 0.030975421890616417]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}