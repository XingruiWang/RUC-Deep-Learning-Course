{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmlSRL0jbID6+q7GI8Wrm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingruiWang/RUC-Deep-Learning-Course/blob/master/Homework/HW_4/homework_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAD79lKDIVQw"
      },
      "source": [
        "# Homework 4: Comparation Between Different Optimazors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XsH6fC-Hv0I",
        "outputId": "7e05c07d-4a09-4b38-8b50-dfdce010b033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive/RUC/DeepLearning/course7\n",
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/RUC/DeepLearning/course7\n",
            "data_facescore\tdata_foodscore\tFoodScore.csv  程序\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDZrYqTbIJ2R"
      },
      "source": [
        "### 1. Loading required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAmj28XAH8wD"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import Model, Input\n",
        "from keras.layers import Dense,Flatten,Input\n",
        "from keras.optimizers import SGD,RMSprop,Adam\n",
        "\n",
        "from keras.utils import to_categorical "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8LDwgj5IvkF",
        "outputId": "0bf5519f-a12f-4ff0-ed7c-7fe83cce4b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## loading mnist dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
        "\n",
        "## One-hot encode y label\n",
        "Y_train=to_categorical(y_train)\n",
        "Y_test=to_categorical(y_test)\n",
        "\n",
        "print(Y_train.shape) # 60000 * 10. 60000 means the amount of data, 10 means 10 classes of number in dataset.\n",
        "print(Y_train[0]) # [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] means number 5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYlRvV9cKKDl"
      },
      "source": [
        "### Model in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vALzfTkqNBML"
      },
      "source": [
        "Model structure: a two-layer neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t01y8pDKF0N"
      },
      "source": [
        "def NNModel(IMSIZE = 28, p = 1000, q = 10):  \n",
        "    '''\n",
        "    Description: Define the model\n",
        "    ----------------------\n",
        "    Args:\n",
        "        IMSIZE: the size of input image, the width and height are same here.\n",
        "        p: the number of neurons in first hidden layer, defult value is 1000\n",
        "        q: the number of neurons in output layer，defult value is 10 since there are 10 classes.\n",
        "    ----------------------\n",
        "    return:\n",
        "        model: the keras model\n",
        "    ----------------------\n",
        "    Usages:\n",
        "    >>> model = NNModel(28, 1000, 10)\n",
        "\n",
        "    '''                                            \n",
        "    input_layer = Input([IMSIZE,IMSIZE])         # the size of a MNIST image is 28 * 28 * 1\n",
        "    x = input_layer                              \n",
        "    x = Flatten()(input_layer)                   # flatten the Tensor (28*28*1) to a vetor (784 * 1)\n",
        "    x = Dense(1000,activation = 'relu')(x)       # hidden layer: fully connection (1000 neurons) + relu\n",
        "    x = Dense(10,activation = 'softmax')(x)      # output layer，fully connection (10 neurons) + softmax, output value range from 0 to 1\n",
        "    output_layer = x\n",
        "    model=Model(input_layer,output_layer)        # connect the input layer, hidden layer and output layer.\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y_0_8g6WVCi"
      },
      "source": [
        "def Momentum(lr, momentum = 0.5):\n",
        "    '''\n",
        "    Momentum optimizer, defined by keras.optimizers.SGD() function with the parameter `momentum > 0`\n",
        "    '''\n",
        "    return SGD(lr = lr, momentum = momentum)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8gjIf9QATK"
      },
      "source": [
        "def train(model, X_train, X_test, y_train, y_test,\n",
        "            batch_size = 128, epochs = 50,\n",
        "            opt = SGD, lr = 0.001, \n",
        "            loss_type = \"categorical_crossentropy\",\n",
        "            metrics = ['accuracy']):\n",
        "    '''\n",
        "    Desctiption: Training function. Compile the model with different optimizers\n",
        "    ------------------------------------------------\n",
        "    Parameter:\n",
        "        model: keras Model\n",
        "        X_train, X_test, y_train, y_test: <numpy.array> training set and validation set, \n",
        "        batch_size: <int> batch size, defualt value is 128\n",
        "        epochs: <int> maximum epochs of training, defualt value is 50\n",
        "        opt: optimizer function, e.g. keras.optimizers.SGD\n",
        "        lr: learning rate, default value is 0.001\n",
        "        loss_type: <string> the name of loss function, for the classification task here, default value is 'categorical_crossentropy'\n",
        "        metrics: <string> the name of matric, for the classification task here, default value is 'accuracy'\n",
        "    -------------------------------------------------\n",
        "    return:\n",
        "        model: the keras model\n",
        "        train_loss: <list>\n",
        "        val_loss: <list>\n",
        "        train_auc: <list>\n",
        "        val_auc: <list>\n",
        "    '''\n",
        "\n",
        "    model.compile(loss = loss_type, optimizer = opt(lr = lr), metrics = metrics)\n",
        "    history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size = batch_size, epochs = epochs, verbose = 2)\n",
        "    \n",
        "    train_loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    train_auc = history.history[\"accuracy\"]\n",
        "    val_auc = history.history[\"val_accuracy\"]\n",
        "    \n",
        "    return model, train_loss, val_loss, train_auc, val_auc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJWwcbWISCnk"
      },
      "source": [
        "def render_loss(losses, name):\n",
        "    t = np.arange(len(losses[0]))\n",
        "    for i, loss in enumerate(losses):\n",
        "        print(i, loss)\n",
        "        plt.plot(t, loss, label = name[i])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('loss') \n",
        "    plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0faVky43T0QI",
        "outputId": "6686deea-8ceb-4582-f653-21119075444e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimizors = [\"SGD\", \"Momentum\", \"RMSprop\", \"Adam\"]\n",
        "losses = [None] * 4\n",
        "\n",
        "for i, opt in enumerate(optimizors):\n",
        "    print(\"=====================================\\nTraining %s \\n\"%(opt))\n",
        "    model = NNModel()\n",
        "    model, loss = train(model,  X_train, X_test, Y_train, Y_test, opt = eval(optimizors[i]))\n",
        "    losses[i] = loss"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SGD \n",
            "Model: \"functional_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 5.6147 - accuracy: 0.8972 - val_loss: 1.0238 - val_accuracy: 0.9305\n",
            "Epoch 2/50\n",
            "469/469 - 1s - loss: 0.5155 - accuracy: 0.9537 - val_loss: 0.7417 - val_accuracy: 0.9430\n",
            "Epoch 3/50\n",
            "469/469 - 1s - loss: 0.2594 - accuracy: 0.9699 - val_loss: 0.6099 - val_accuracy: 0.9489\n",
            "Epoch 4/50\n",
            "469/469 - 1s - loss: 0.1384 - accuracy: 0.9789 - val_loss: 0.5817 - val_accuracy: 0.9511\n",
            "Epoch 5/50\n",
            "469/469 - 1s - loss: 0.0778 - accuracy: 0.9864 - val_loss: 0.5510 - val_accuracy: 0.9514\n",
            "Epoch 6/50\n",
            "469/469 - 1s - loss: 0.0433 - accuracy: 0.9911 - val_loss: 0.5191 - val_accuracy: 0.9536\n",
            "Epoch 7/50\n",
            "469/469 - 1s - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.5154 - val_accuracy: 0.9540\n",
            "Epoch 8/50\n",
            "469/469 - 1s - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.5127 - val_accuracy: 0.9550\n",
            "Epoch 9/50\n",
            "469/469 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.5091 - val_accuracy: 0.9549\n",
            "Epoch 10/50\n",
            "469/469 - 1s - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.5042 - val_accuracy: 0.9556\n",
            "Epoch 11/50\n",
            "469/469 - 1s - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.5044 - val_accuracy: 0.9556\n",
            "Epoch 12/50\n",
            "469/469 - 1s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.5060 - val_accuracy: 0.9557\n",
            "Epoch 13/50\n",
            "469/469 - 1s - loss: 9.0604e-04 - accuracy: 0.9999 - val_loss: 0.5060 - val_accuracy: 0.9561\n",
            "Epoch 14/50\n",
            "469/469 - 1s - loss: 7.7657e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9563\n",
            "Epoch 15/50\n",
            "469/469 - 1s - loss: 6.9743e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9560\n",
            "Epoch 16/50\n",
            "469/469 - 1s - loss: 6.3094e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9562\n",
            "Epoch 17/50\n",
            "469/469 - 1s - loss: 5.8421e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9561\n",
            "Epoch 18/50\n",
            "469/469 - 1s - loss: 5.4189e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9561\n",
            "Epoch 19/50\n",
            "469/469 - 1s - loss: 5.0843e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9561\n",
            "Epoch 20/50\n",
            "469/469 - 1s - loss: 4.8015e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9561\n",
            "Epoch 21/50\n",
            "469/469 - 1s - loss: 4.5412e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9563\n",
            "Epoch 22/50\n",
            "469/469 - 1s - loss: 4.3094e-04 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9563\n",
            "Epoch 23/50\n",
            "469/469 - 1s - loss: 4.1068e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9566\n",
            "Epoch 24/50\n",
            "469/469 - 1s - loss: 3.9438e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9564\n",
            "Epoch 25/50\n",
            "469/469 - 1s - loss: 3.7790e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9564\n",
            "Epoch 26/50\n",
            "469/469 - 1s - loss: 3.6427e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9566\n",
            "Epoch 27/50\n",
            "469/469 - 1s - loss: 3.5007e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9568\n",
            "Epoch 28/50\n",
            "469/469 - 1s - loss: 3.3865e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9566\n",
            "Epoch 29/50\n",
            "469/469 - 1s - loss: 3.2626e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9568\n",
            "Epoch 30/50\n",
            "469/469 - 1s - loss: 3.1725e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9567\n",
            "Epoch 31/50\n",
            "469/469 - 1s - loss: 3.0567e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9570\n",
            "Epoch 32/50\n",
            "469/469 - 1s - loss: 2.9837e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9569\n",
            "Epoch 33/50\n",
            "469/469 - 1s - loss: 2.8882e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9572\n",
            "Epoch 34/50\n",
            "469/469 - 1s - loss: 2.8173e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9572\n",
            "Epoch 35/50\n",
            "469/469 - 1s - loss: 2.7369e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9573\n",
            "Epoch 36/50\n",
            "469/469 - 1s - loss: 2.6664e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9573\n",
            "Epoch 37/50\n",
            "469/469 - 1s - loss: 2.6009e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9573\n",
            "Epoch 38/50\n",
            "469/469 - 1s - loss: 2.5349e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9573\n",
            "Epoch 39/50\n",
            "469/469 - 1s - loss: 2.4756e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9573\n",
            "Epoch 40/50\n",
            "469/469 - 1s - loss: 2.4228e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9573\n",
            "Epoch 41/50\n",
            "469/469 - 1s - loss: 2.3716e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9575\n",
            "Epoch 42/50\n",
            "469/469 - 1s - loss: 2.3174e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9573\n",
            "Epoch 43/50\n",
            "469/469 - 1s - loss: 2.2690e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9574\n",
            "Epoch 44/50\n",
            "469/469 - 1s - loss: 2.2238e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9575\n",
            "Epoch 45/50\n",
            "469/469 - 1s - loss: 2.1797e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9572\n",
            "Epoch 46/50\n",
            "469/469 - 1s - loss: 2.1371e-04 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9576\n",
            "Epoch 47/50\n",
            "469/469 - 1s - loss: 2.0969e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9575\n",
            "Epoch 48/50\n",
            "469/469 - 1s - loss: 2.0568e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9578\n",
            "Epoch 49/50\n",
            "469/469 - 1s - loss: 2.0200e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9577\n",
            "Epoch 50/50\n",
            "469/469 - 1s - loss: 1.9862e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9577\n",
            "Training Momentum \n",
            "Model: \"functional_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 5.1747 - accuracy: 0.8935 - val_loss: 0.4641 - val_accuracy: 0.9306\n",
            "Epoch 2/50\n",
            "469/469 - 1s - loss: 0.2637 - accuracy: 0.9502 - val_loss: 0.3634 - val_accuracy: 0.9406\n",
            "Epoch 3/50\n",
            "469/469 - 1s - loss: 0.1381 - accuracy: 0.9683 - val_loss: 0.3302 - val_accuracy: 0.9456\n",
            "Epoch 4/50\n",
            "469/469 - 1s - loss: 0.0821 - accuracy: 0.9783 - val_loss: 0.2963 - val_accuracy: 0.9502\n",
            "Epoch 5/50\n",
            "469/469 - 1s - loss: 0.0529 - accuracy: 0.9861 - val_loss: 0.2876 - val_accuracy: 0.9523\n",
            "Epoch 6/50\n",
            "469/469 - 1s - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.2782 - val_accuracy: 0.9539\n",
            "Epoch 7/50\n",
            "469/469 - 1s - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.2736 - val_accuracy: 0.9555\n",
            "Epoch 8/50\n",
            "469/469 - 1s - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.2751 - val_accuracy: 0.9555\n",
            "Epoch 9/50\n",
            "469/469 - 1s - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.2726 - val_accuracy: 0.9570\n",
            "Epoch 10/50\n",
            "469/469 - 1s - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.2715 - val_accuracy: 0.9578\n",
            "Epoch 11/50\n",
            "469/469 - 1s - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.2670 - val_accuracy: 0.9601\n",
            "Epoch 12/50\n",
            "469/469 - 1s - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.2674 - val_accuracy: 0.9601\n",
            "Epoch 13/50\n",
            "469/469 - 1s - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.2693 - val_accuracy: 0.9601\n",
            "Epoch 14/50\n",
            "469/469 - 1s - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.2681 - val_accuracy: 0.9610\n",
            "Epoch 15/50\n",
            "469/469 - 1s - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.2686 - val_accuracy: 0.9612\n",
            "Epoch 16/50\n",
            "469/469 - 1s - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.2698 - val_accuracy: 0.9610\n",
            "Epoch 17/50\n",
            "469/469 - 1s - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.2706 - val_accuracy: 0.9620\n",
            "Epoch 18/50\n",
            "469/469 - 1s - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.2687 - val_accuracy: 0.9624\n",
            "Epoch 19/50\n",
            "469/469 - 1s - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.2707 - val_accuracy: 0.9627\n",
            "Epoch 20/50\n",
            "469/469 - 1s - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.2703 - val_accuracy: 0.9630\n",
            "Epoch 21/50\n",
            "469/469 - 1s - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.2717 - val_accuracy: 0.9625\n",
            "Epoch 22/50\n",
            "469/469 - 1s - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.2708 - val_accuracy: 0.9630\n",
            "Epoch 23/50\n",
            "469/469 - 1s - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.2715 - val_accuracy: 0.9632\n",
            "Epoch 24/50\n",
            "469/469 - 1s - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.2716 - val_accuracy: 0.9631\n",
            "Epoch 25/50\n",
            "469/469 - 1s - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2727 - val_accuracy: 0.9635\n",
            "Epoch 26/50\n",
            "469/469 - 1s - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.2729 - val_accuracy: 0.9634\n",
            "Epoch 27/50\n",
            "469/469 - 1s - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.2729 - val_accuracy: 0.9635\n",
            "Epoch 28/50\n",
            "469/469 - 1s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.2732 - val_accuracy: 0.9634\n",
            "Epoch 29/50\n",
            "469/469 - 1s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2740 - val_accuracy: 0.9634\n",
            "Epoch 30/50\n",
            "469/469 - 1s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.2737 - val_accuracy: 0.9635\n",
            "Epoch 31/50\n",
            "469/469 - 1s - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2745 - val_accuracy: 0.9642\n",
            "Epoch 32/50\n",
            "469/469 - 1s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2747 - val_accuracy: 0.9633\n",
            "Epoch 33/50\n",
            "469/469 - 1s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.2748 - val_accuracy: 0.9637\n",
            "Epoch 34/50\n",
            "469/469 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9645\n",
            "Epoch 35/50\n",
            "469/469 - 1s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.2750 - val_accuracy: 0.9641\n",
            "Epoch 36/50\n",
            "469/469 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9641\n",
            "Epoch 37/50\n",
            "469/469 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9641\n",
            "Epoch 38/50\n",
            "469/469 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9640\n",
            "Epoch 39/50\n",
            "469/469 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9641\n",
            "Epoch 40/50\n",
            "469/469 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9641\n",
            "Epoch 41/50\n",
            "469/469 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9643\n",
            "Epoch 42/50\n",
            "469/469 - 1s - loss: 9.9200e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9643\n",
            "Epoch 43/50\n",
            "469/469 - 1s - loss: 9.5650e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9644\n",
            "Epoch 44/50\n",
            "469/469 - 1s - loss: 9.2240e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9644\n",
            "Epoch 45/50\n",
            "469/469 - 1s - loss: 8.9423e-04 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9640\n",
            "Epoch 46/50\n",
            "469/469 - 1s - loss: 8.6776e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9642\n",
            "Epoch 47/50\n",
            "469/469 - 1s - loss: 8.3690e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9642\n",
            "Epoch 48/50\n",
            "469/469 - 1s - loss: 8.1163e-04 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9641\n",
            "Epoch 49/50\n",
            "469/469 - 1s - loss: 7.8880e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9642\n",
            "Epoch 50/50\n",
            "469/469 - 1s - loss: 7.6551e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9644\n",
            "Training RMSprop \n",
            "Model: \"functional_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 5.9239 - accuracy: 0.9061 - val_loss: 1.1098 - val_accuracy: 0.9347\n",
            "Epoch 2/50\n",
            "469/469 - 1s - loss: 0.7001 - accuracy: 0.9554 - val_loss: 0.7751 - val_accuracy: 0.9542\n",
            "Epoch 3/50\n",
            "469/469 - 1s - loss: 0.4930 - accuracy: 0.9659 - val_loss: 0.7602 - val_accuracy: 0.9556\n",
            "Epoch 4/50\n",
            "469/469 - 1s - loss: 0.3993 - accuracy: 0.9730 - val_loss: 0.5466 - val_accuracy: 0.9668\n",
            "Epoch 5/50\n",
            "469/469 - 1s - loss: 0.3314 - accuracy: 0.9775 - val_loss: 0.8031 - val_accuracy: 0.9607\n",
            "Epoch 6/50\n",
            "469/469 - 1s - loss: 0.3125 - accuracy: 0.9809 - val_loss: 0.9543 - val_accuracy: 0.9602\n",
            "Epoch 7/50\n",
            "469/469 - 1s - loss: 0.2998 - accuracy: 0.9829 - val_loss: 0.7329 - val_accuracy: 0.9703\n",
            "Epoch 8/50\n",
            "469/469 - 1s - loss: 0.2828 - accuracy: 0.9850 - val_loss: 0.8985 - val_accuracy: 0.9708\n",
            "Epoch 9/50\n",
            "469/469 - 1s - loss: 0.2608 - accuracy: 0.9859 - val_loss: 0.9308 - val_accuracy: 0.9698\n",
            "Epoch 10/50\n",
            "469/469 - 1s - loss: 0.2376 - accuracy: 0.9878 - val_loss: 0.7168 - val_accuracy: 0.9785\n",
            "Epoch 11/50\n",
            "469/469 - 1s - loss: 0.2107 - accuracy: 0.9883 - val_loss: 0.9349 - val_accuracy: 0.9724\n",
            "Epoch 12/50\n",
            "469/469 - 1s - loss: 0.1891 - accuracy: 0.9907 - val_loss: 0.8863 - val_accuracy: 0.9745\n",
            "Epoch 13/50\n",
            "469/469 - 1s - loss: 0.1870 - accuracy: 0.9905 - val_loss: 0.9935 - val_accuracy: 0.9767\n",
            "Epoch 14/50\n",
            "469/469 - 1s - loss: 0.2035 - accuracy: 0.9906 - val_loss: 0.9032 - val_accuracy: 0.9749\n",
            "Epoch 15/50\n",
            "469/469 - 1s - loss: 0.1885 - accuracy: 0.9910 - val_loss: 1.0490 - val_accuracy: 0.9737\n",
            "Epoch 16/50\n",
            "469/469 - 1s - loss: 0.1526 - accuracy: 0.9927 - val_loss: 1.1832 - val_accuracy: 0.9764\n",
            "Epoch 17/50\n",
            "469/469 - 1s - loss: 0.1517 - accuracy: 0.9926 - val_loss: 1.0433 - val_accuracy: 0.9761\n",
            "Epoch 18/50\n",
            "469/469 - 1s - loss: 0.1710 - accuracy: 0.9927 - val_loss: 1.2076 - val_accuracy: 0.9717\n",
            "Epoch 19/50\n",
            "469/469 - 1s - loss: 0.1311 - accuracy: 0.9936 - val_loss: 1.1955 - val_accuracy: 0.9750\n",
            "Epoch 20/50\n",
            "469/469 - 1s - loss: 0.1273 - accuracy: 0.9941 - val_loss: 1.2263 - val_accuracy: 0.9778\n",
            "Epoch 21/50\n",
            "469/469 - 1s - loss: 0.1424 - accuracy: 0.9941 - val_loss: 1.1582 - val_accuracy: 0.9758\n",
            "Epoch 22/50\n",
            "469/469 - 1s - loss: 0.1029 - accuracy: 0.9948 - val_loss: 1.3579 - val_accuracy: 0.9759\n",
            "Epoch 23/50\n",
            "469/469 - 1s - loss: 0.1248 - accuracy: 0.9945 - val_loss: 1.2932 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "469/469 - 1s - loss: 0.1268 - accuracy: 0.9947 - val_loss: 1.4899 - val_accuracy: 0.9720\n",
            "Epoch 25/50\n",
            "469/469 - 1s - loss: 0.1207 - accuracy: 0.9951 - val_loss: 1.3563 - val_accuracy: 0.9781\n",
            "Epoch 26/50\n",
            "469/469 - 1s - loss: 0.0909 - accuracy: 0.9961 - val_loss: 1.6189 - val_accuracy: 0.9716\n",
            "Epoch 27/50\n",
            "469/469 - 1s - loss: 0.0878 - accuracy: 0.9959 - val_loss: 1.3333 - val_accuracy: 0.9773\n",
            "Epoch 28/50\n",
            "469/469 - 1s - loss: 0.0951 - accuracy: 0.9962 - val_loss: 1.1828 - val_accuracy: 0.9795\n",
            "Epoch 29/50\n",
            "469/469 - 1s - loss: 0.1038 - accuracy: 0.9958 - val_loss: 1.5609 - val_accuracy: 0.9765\n",
            "Epoch 30/50\n",
            "469/469 - 1s - loss: 0.0893 - accuracy: 0.9962 - val_loss: 1.4332 - val_accuracy: 0.9770\n",
            "Epoch 31/50\n",
            "469/469 - 1s - loss: 0.0948 - accuracy: 0.9964 - val_loss: 1.2631 - val_accuracy: 0.9815\n",
            "Epoch 32/50\n",
            "469/469 - 1s - loss: 0.0812 - accuracy: 0.9967 - val_loss: 1.5600 - val_accuracy: 0.9768\n",
            "Epoch 33/50\n",
            "469/469 - 1s - loss: 0.0857 - accuracy: 0.9968 - val_loss: 1.4461 - val_accuracy: 0.9784\n",
            "Epoch 34/50\n",
            "469/469 - 1s - loss: 0.0948 - accuracy: 0.9966 - val_loss: 1.5778 - val_accuracy: 0.9777\n",
            "Epoch 35/50\n",
            "469/469 - 1s - loss: 0.0804 - accuracy: 0.9963 - val_loss: 1.3585 - val_accuracy: 0.9797\n",
            "Epoch 36/50\n",
            "469/469 - 1s - loss: 0.0924 - accuracy: 0.9967 - val_loss: 1.5381 - val_accuracy: 0.9792\n",
            "Epoch 37/50\n",
            "469/469 - 1s - loss: 0.0813 - accuracy: 0.9969 - val_loss: 1.4839 - val_accuracy: 0.9793\n",
            "Epoch 38/50\n",
            "469/469 - 1s - loss: 0.0725 - accuracy: 0.9969 - val_loss: 1.5315 - val_accuracy: 0.9761\n",
            "Epoch 39/50\n",
            "469/469 - 1s - loss: 0.0738 - accuracy: 0.9971 - val_loss: 1.4989 - val_accuracy: 0.9788\n",
            "Epoch 40/50\n",
            "469/469 - 1s - loss: 0.0732 - accuracy: 0.9971 - val_loss: 1.6932 - val_accuracy: 0.9765\n",
            "Epoch 41/50\n",
            "469/469 - 1s - loss: 0.0583 - accuracy: 0.9975 - val_loss: 1.6041 - val_accuracy: 0.9776\n",
            "Epoch 42/50\n",
            "469/469 - 1s - loss: 0.0653 - accuracy: 0.9972 - val_loss: 1.6095 - val_accuracy: 0.9792\n",
            "Epoch 43/50\n",
            "469/469 - 1s - loss: 0.0647 - accuracy: 0.9974 - val_loss: 1.5543 - val_accuracy: 0.9803\n",
            "Epoch 44/50\n",
            "469/469 - 1s - loss: 0.0790 - accuracy: 0.9974 - val_loss: 1.6177 - val_accuracy: 0.9799\n",
            "Epoch 45/50\n",
            "469/469 - 1s - loss: 0.0598 - accuracy: 0.9977 - val_loss: 1.7437 - val_accuracy: 0.9789\n",
            "Epoch 46/50\n",
            "469/469 - 1s - loss: 0.0522 - accuracy: 0.9978 - val_loss: 1.6065 - val_accuracy: 0.9798\n",
            "Epoch 47/50\n",
            "469/469 - 1s - loss: 0.0611 - accuracy: 0.9977 - val_loss: 1.6383 - val_accuracy: 0.9803\n",
            "Epoch 48/50\n",
            "469/469 - 1s - loss: 0.0559 - accuracy: 0.9979 - val_loss: 1.7989 - val_accuracy: 0.9784\n",
            "Epoch 49/50\n",
            "469/469 - 1s - loss: 0.0446 - accuracy: 0.9982 - val_loss: 1.6899 - val_accuracy: 0.9799\n",
            "Epoch 50/50\n",
            "469/469 - 1s - loss: 0.0513 - accuracy: 0.9980 - val_loss: 1.8694 - val_accuracy: 0.9785\n",
            "Training Adam \n",
            "Model: \"functional_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 5.0746 - accuracy: 0.9128 - val_loss: 0.9242 - val_accuracy: 0.9464\n",
            "Epoch 2/50\n",
            "469/469 - 1s - loss: 0.4854 - accuracy: 0.9608 - val_loss: 0.6091 - val_accuracy: 0.9544\n",
            "Epoch 3/50\n",
            "469/469 - 1s - loss: 0.2810 - accuracy: 0.9708 - val_loss: 0.4836 - val_accuracy: 0.9592\n",
            "Epoch 4/50\n",
            "469/469 - 1s - loss: 0.1735 - accuracy: 0.9773 - val_loss: 0.4463 - val_accuracy: 0.9615\n",
            "Epoch 5/50\n",
            "469/469 - 1s - loss: 0.2143 - accuracy: 0.9748 - val_loss: 0.4244 - val_accuracy: 0.9637\n",
            "Epoch 6/50\n",
            "469/469 - 1s - loss: 0.1967 - accuracy: 0.9779 - val_loss: 0.4756 - val_accuracy: 0.9651\n",
            "Epoch 7/50\n",
            "469/469 - 1s - loss: 0.1834 - accuracy: 0.9783 - val_loss: 0.4720 - val_accuracy: 0.9639\n",
            "Epoch 8/50\n",
            "469/469 - 1s - loss: 0.1926 - accuracy: 0.9777 - val_loss: 0.4518 - val_accuracy: 0.9656\n",
            "Epoch 9/50\n",
            "469/469 - 1s - loss: 0.2019 - accuracy: 0.9776 - val_loss: 0.5095 - val_accuracy: 0.9621\n",
            "Epoch 10/50\n",
            "469/469 - 1s - loss: 0.2014 - accuracy: 0.9783 - val_loss: 0.5196 - val_accuracy: 0.9630\n",
            "Epoch 11/50\n",
            "469/469 - 1s - loss: 0.2121 - accuracy: 0.9789 - val_loss: 0.5051 - val_accuracy: 0.9668\n",
            "Epoch 12/50\n",
            "469/469 - 1s - loss: 0.2009 - accuracy: 0.9796 - val_loss: 0.4391 - val_accuracy: 0.9725\n",
            "Epoch 13/50\n",
            "469/469 - 1s - loss: 0.2258 - accuracy: 0.9800 - val_loss: 0.6825 - val_accuracy: 0.9676\n",
            "Epoch 14/50\n",
            "469/469 - 1s - loss: 0.2050 - accuracy: 0.9819 - val_loss: 0.5993 - val_accuracy: 0.9698\n",
            "Epoch 15/50\n",
            "469/469 - 1s - loss: 0.1880 - accuracy: 0.9831 - val_loss: 0.5438 - val_accuracy: 0.9727\n",
            "Epoch 16/50\n",
            "469/469 - 1s - loss: 0.1890 - accuracy: 0.9842 - val_loss: 0.6505 - val_accuracy: 0.9705\n",
            "Epoch 17/50\n",
            "469/469 - 1s - loss: 0.1700 - accuracy: 0.9854 - val_loss: 0.5903 - val_accuracy: 0.9702\n",
            "Epoch 18/50\n",
            "469/469 - 1s - loss: 0.1331 - accuracy: 0.9873 - val_loss: 0.5914 - val_accuracy: 0.9726\n",
            "Epoch 19/50\n",
            "469/469 - 1s - loss: 0.1297 - accuracy: 0.9881 - val_loss: 0.7629 - val_accuracy: 0.9705\n",
            "Epoch 20/50\n",
            "469/469 - 1s - loss: 0.1605 - accuracy: 0.9874 - val_loss: 0.8068 - val_accuracy: 0.9654\n",
            "Epoch 21/50\n",
            "469/469 - 1s - loss: 0.1475 - accuracy: 0.9886 - val_loss: 0.7343 - val_accuracy: 0.9720\n",
            "Epoch 22/50\n",
            "469/469 - 1s - loss: 0.1810 - accuracy: 0.9874 - val_loss: 0.8221 - val_accuracy: 0.9700\n",
            "Epoch 23/50\n",
            "469/469 - 1s - loss: 0.1692 - accuracy: 0.9887 - val_loss: 0.8836 - val_accuracy: 0.9704\n",
            "Epoch 24/50\n",
            "469/469 - 1s - loss: 0.1255 - accuracy: 0.9898 - val_loss: 0.8344 - val_accuracy: 0.9717\n",
            "Epoch 25/50\n",
            "469/469 - 1s - loss: 0.1336 - accuracy: 0.9905 - val_loss: 0.8603 - val_accuracy: 0.9747\n",
            "Epoch 26/50\n",
            "469/469 - 1s - loss: 0.1320 - accuracy: 0.9909 - val_loss: 0.8228 - val_accuracy: 0.9745\n",
            "Epoch 27/50\n",
            "469/469 - 1s - loss: 0.1084 - accuracy: 0.9923 - val_loss: 0.7900 - val_accuracy: 0.9760\n",
            "Epoch 28/50\n",
            "469/469 - 1s - loss: 0.1279 - accuracy: 0.9911 - val_loss: 0.8765 - val_accuracy: 0.9747\n",
            "Epoch 29/50\n",
            "469/469 - 1s - loss: 0.1518 - accuracy: 0.9912 - val_loss: 1.0677 - val_accuracy: 0.9739\n",
            "Epoch 30/50\n",
            "469/469 - 1s - loss: 0.1357 - accuracy: 0.9922 - val_loss: 1.0478 - val_accuracy: 0.9763\n",
            "Epoch 31/50\n",
            "469/469 - 1s - loss: 0.1291 - accuracy: 0.9924 - val_loss: 1.0342 - val_accuracy: 0.9757\n",
            "Epoch 32/50\n",
            "469/469 - 1s - loss: 0.1332 - accuracy: 0.9923 - val_loss: 1.0341 - val_accuracy: 0.9760\n",
            "Epoch 33/50\n",
            "469/469 - 1s - loss: 0.1405 - accuracy: 0.9926 - val_loss: 1.1223 - val_accuracy: 0.9743\n",
            "Epoch 34/50\n",
            "469/469 - 1s - loss: 0.1141 - accuracy: 0.9939 - val_loss: 1.1076 - val_accuracy: 0.9732\n",
            "Epoch 35/50\n",
            "469/469 - 1s - loss: 0.1131 - accuracy: 0.9935 - val_loss: 1.2445 - val_accuracy: 0.9755\n",
            "Epoch 36/50\n",
            "469/469 - 1s - loss: 0.1433 - accuracy: 0.9930 - val_loss: 1.4161 - val_accuracy: 0.9753\n",
            "Epoch 37/50\n",
            "469/469 - 1s - loss: 0.1140 - accuracy: 0.9937 - val_loss: 1.2944 - val_accuracy: 0.9738\n",
            "Epoch 38/50\n",
            "469/469 - 1s - loss: 0.0906 - accuracy: 0.9949 - val_loss: 1.2381 - val_accuracy: 0.9775\n",
            "Epoch 39/50\n",
            "469/469 - 1s - loss: 0.1002 - accuracy: 0.9944 - val_loss: 1.4847 - val_accuracy: 0.9745\n",
            "Epoch 40/50\n",
            "469/469 - 1s - loss: 0.1097 - accuracy: 0.9943 - val_loss: 1.2729 - val_accuracy: 0.9767\n",
            "Epoch 41/50\n",
            "469/469 - 1s - loss: 0.1124 - accuracy: 0.9942 - val_loss: 1.5119 - val_accuracy: 0.9751\n",
            "Epoch 42/50\n",
            "469/469 - 1s - loss: 0.1103 - accuracy: 0.9948 - val_loss: 1.6717 - val_accuracy: 0.9724\n",
            "Epoch 43/50\n",
            "469/469 - 1s - loss: 0.1293 - accuracy: 0.9941 - val_loss: 1.5255 - val_accuracy: 0.9761\n",
            "Epoch 44/50\n",
            "469/469 - 1s - loss: 0.1067 - accuracy: 0.9952 - val_loss: 1.6253 - val_accuracy: 0.9757\n",
            "Epoch 45/50\n",
            "469/469 - 1s - loss: 0.1259 - accuracy: 0.9946 - val_loss: 1.7452 - val_accuracy: 0.9762\n",
            "Epoch 46/50\n",
            "469/469 - 1s - loss: 0.0992 - accuracy: 0.9955 - val_loss: 1.9057 - val_accuracy: 0.9754\n",
            "Epoch 47/50\n",
            "469/469 - 1s - loss: 0.1044 - accuracy: 0.9959 - val_loss: 1.8045 - val_accuracy: 0.9772\n",
            "Epoch 48/50\n",
            "469/469 - 1s - loss: 0.1193 - accuracy: 0.9957 - val_loss: 1.3408 - val_accuracy: 0.9791\n",
            "Epoch 49/50\n",
            "469/469 - 1s - loss: 0.0838 - accuracy: 0.9960 - val_loss: 1.5581 - val_accuracy: 0.9787\n",
            "Epoch 50/50\n",
            "469/469 - 1s - loss: 0.0870 - accuracy: 0.9961 - val_loss: 1.7476 - val_accuracy: 0.9753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Cg5CRbXBAd",
        "outputId": "fcfb6f52-c0c5-4110-ca89-20623fc12e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "render_loss(losses, optimizors)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [5.6147003173828125, 0.515451967716217, 0.2594027817249298, 0.13841107487678528, 0.07777862250804901, 0.04330785572528839, 0.02310206927359104, 0.012133508920669556, 0.006132724229246378, 0.003540530800819397, 0.002075823489576578, 0.001222580554895103, 0.000906040077097714, 0.0007765725022181869, 0.0006974345305934548, 0.000630939204711467, 0.0005842123064212501, 0.0005418896907940507, 0.0005084273288957775, 0.00048015432548709214, 0.0004541229864116758, 0.0004309403302613646, 0.00041068284190259874, 0.0003943846095353365, 0.0003778950194828212, 0.0003642712254077196, 0.00035007038968615234, 0.0003386532480362803, 0.00032625708263367414, 0.00031725186272524297, 0.00030567459180019796, 0.0002983728190883994, 0.000288819195702672, 0.00028173456666991115, 0.00027368534938432276, 0.0002666435029823333, 0.00026009028078988194, 0.0002534922678023577, 0.00024755578488111496, 0.00024227668473031372, 0.00023715666611678898, 0.00023174074885901064, 0.00022689611068926752, 0.0002223826159024611, 0.00021797322551719844, 0.00021370622562244534, 0.00020969280740246177, 0.00020568112086039037, 0.00020199507707729936, 0.00019862261251546443]\n",
            "1 [5.1747145652771, 0.26366886496543884, 0.13805437088012695, 0.08211397379636765, 0.05287328362464905, 0.03670169785618782, 0.02666865661740303, 0.02031528577208519, 0.015866341069340706, 0.01287619024515152, 0.010735762305557728, 0.009078118950128555, 0.007752793375402689, 0.006774452049285173, 0.0059789856895804405, 0.00531901977956295, 0.0047414242289960384, 0.004228413105010986, 0.0038093237672001123, 0.0035055435728281736, 0.003176033264026046, 0.002894355682656169, 0.002676786622032523, 0.0024958131834864616, 0.0022875217255204916, 0.002148696454241872, 0.0019960321951657534, 0.0018864644225686789, 0.0017804228700697422, 0.0016694205114617944, 0.0015870992792770267, 0.0014923596754670143, 0.0014246705686673522, 0.0013667891034856439, 0.0013070052955299616, 0.001256660558283329, 0.001195223769173026, 0.0011574144009500742, 0.0011049455497413874, 0.0010728795314207673, 0.0010263730073347688, 0.000992002198472619, 0.0009565048385411501, 0.000922398641705513, 0.0008942275308072567, 0.0008677581790834665, 0.0008368968265131116, 0.0008116268436424434, 0.000788797449786216, 0.0007655084482394159]\n",
            "2 [5.923880100250244, 0.7001177072525024, 0.4930166006088257, 0.39925503730773926, 0.33136242628097534, 0.31246432662010193, 0.29975464940071106, 0.2827973961830139, 0.2608430087566376, 0.23762457072734833, 0.21070344746112823, 0.18909227848052979, 0.18704365193843842, 0.20351219177246094, 0.18845120072364807, 0.15259532630443573, 0.15172967314720154, 0.17099297046661377, 0.13113771378993988, 0.12725242972373962, 0.142361119389534, 0.10293193906545639, 0.12483488768339157, 0.1267690658569336, 0.12066606432199478, 0.0908779576420784, 0.08778617531061172, 0.0950685515999794, 0.103777214884758, 0.08930937200784683, 0.09482333809137344, 0.08119431138038635, 0.08565449714660645, 0.09477953612804413, 0.08037692308425903, 0.09242387861013412, 0.08127235621213913, 0.07246514409780502, 0.07382391393184662, 0.07323338836431503, 0.05830873176455498, 0.06534359604120255, 0.06469538062810898, 0.07899602502584457, 0.05980765074491501, 0.052194759249687195, 0.06107691675424576, 0.05591857433319092, 0.04455454275012016, 0.05131964385509491]\n",
            "3 [5.07456636428833, 0.4853799343109131, 0.2809666693210602, 0.17347338795661926, 0.21433602273464203, 0.19665546715259552, 0.18344655632972717, 0.1926349401473999, 0.201907217502594, 0.20143790543079376, 0.21212263405323029, 0.2008739709854126, 0.22582551836967468, 0.20498107373714447, 0.18799836933612823, 0.18896938860416412, 0.16998963057994843, 0.13308821618556976, 0.12965352833271027, 0.1605292111635208, 0.1474994570016861, 0.18099576234817505, 0.16924573481082916, 0.12547503411769867, 0.13363699615001678, 0.13204129040241241, 0.10841846466064453, 0.12787805497646332, 0.1517692655324936, 0.1356816440820694, 0.12913386523723602, 0.13321980834007263, 0.14054372906684875, 0.11410889774560928, 0.1131359189748764, 0.14331017434597015, 0.11404816061258316, 0.09063100069761276, 0.100181944668293, 0.10971535742282867, 0.11242824792861938, 0.11026563495397568, 0.12927556037902832, 0.10672459006309509, 0.12594567239284515, 0.09921994805335999, 0.10436675697565079, 0.11929208785295486, 0.08375241607427597, 0.08702688664197922]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}