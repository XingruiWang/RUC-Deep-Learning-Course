{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingruiWang/RUC-Deep-Learning-Course/blob/master/Homework/HW_7/hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLF77xGY0xF4"
      },
      "source": [
        "# 广告效果预测"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbb-7m371DCc"
      },
      "source": [
        "### 背景介绍\n",
        "\n",
        "**搜索引擎营销**（SEM: Search Engine Marketing）的核心是通过搜索引擎上，用户主动输入表达的意愿，推送相应的广告信息。搜索引擎营销运营的关键环节之一就是**关键词拓展**。所谓关键词拓展，就是根据已有的关键词表现数据，推测还有哪些尚未购买的关键词。因此，你需要构造一个从**X = 关键词**到**Y = 广告效果**的回归模型。不同场景下对广告效果的定义个不相同。可能是展现、点击、转化、再购买等。这样就构成了一个完整的销售漏斗。而本案例关注该销售漏斗的第一个环节：展现。具体而言，**因变量是Y=log(展现量)**，直接反映了广告主信息在用户面前暴露的强度。而X就是关键词本身的文本信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J4OKjCx1iUB"
      },
      "source": [
        "### 方法介绍\n",
        "\n",
        "#### 一、分词\n",
        "\n",
        "源数据中x为用户搜索内容，为了更好提取内容的语义信息，我们先将内容分割成不同的汉语词语。分词的工具采用的是python中的Jiba包。\n",
        "\n",
        "#### 二、word to vector\n",
        "\n",
        "在分词之后，我使用word-to-vector词编码模型对文本数据进行量化\n",
        "\n",
        "#### 三、RNN模型\n",
        "\n",
        "<img src = 'https://camo.githubusercontent.com/bee147253f0a81a87f02200007716adaf97943f6/687474703a2f2f6b657875652e666d2f7573722f75706c6f6164732f323031352f30382f323036373734313235372e706e67' width=70%>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMHbwUUI0pRW",
        "outputId": "dbf6b2e4-a7e6-4603-da00-6fc2be47ba0c"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH2r8qq4BmHj"
      },
      "source": [
        "### 模型搭建"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo-cYG3PB0N3"
      },
      "source": [
        "一、数据读入与初步分词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "JM_4mDwxCsA3",
        "outputId": "4a1e4469-b11d-4c5d-8a8b-c606ca309d6e"
      },
      "source": [
        "# drive/MyDrive/RUC/DeepLearning/course7/SEM.csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import jieba\n",
        "import random\n",
        "from collections import Counter\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "data_table = pd.read_csv('drive/MyDrive/RUC/DeepLearning/course7/SEM.csv')\n",
        "sentences, y = data_table[\"kw\"], data_table[\"logImp\"].to_numpy().astype(np.float32)\n",
        "N = len(y)\n",
        "\n",
        "# 数据预处理，归一化\n",
        "y = (y - y.min()) / (y.max() - y.min())\n",
        "train_data = []\n",
        "for s in sentences:\n",
        "  train_data.append(jieba.lcut(s))\n",
        "\n",
        "print(\"-------------- y的分布 -----------------\")\n",
        "plt.hist(y, bins=50, color = \"#0ABAB5\", alpha = 0.6)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n-------------- 分词结果 -----------------\")\n",
        "show_index = random.sample(range(N), 10)\n",
        "for s, cut in zip(sentences[show_index], np.array(train_data)[show_index]):\n",
        "  print(s, \"\\t\", cut)\n",
        "\n",
        "\n",
        "print(\"\\n-------------- 词频前20统计 -----------------\")\n",
        "\n",
        "all_words = np.hstack(train_data)\n",
        "words_count = Counter(all_words)\n",
        "W = len(words_count)\n",
        "print(\"%d words in total\"%(W))\n",
        "print(words_count.most_common(20))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------- y的分布 -----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-------------- 分词结果 -----------------\n",
            "网上预订飞机票 \t ['网上', '预订', '飞机票']\n",
            "特价珠海飞机票 \t ['特价', '珠海', '飞机票']\n",
            "乌鲁木齐便宜机票 \t ['乌鲁木齐', '便宜', '机票']\n",
            "郑州特价机票价格查询 \t ['郑州', '特价机票', '价格', '查询']\n",
            "机票订票 \t ['机票', '订票']\n",
            "晋江特价机票 \t ['晋江', '特价机票']\n",
            "南方航空机票查询 \t ['南方', '航空', '机票', '查询']\n",
            "长沙飞机票多少钱 \t ['长沙', '飞机票', '多少', '钱']\n",
            "怎么买便宜机票 \t ['怎么', '买', '便宜', '机票']\n",
            "上海到九江特价机票 \t ['上海', '到', '九江', '特价机票']\n",
            "\n",
            "-------------- 词频前20统计 -----------------\n",
            "506 words in total\n",
            "[('机票', 1954), ('飞机票', 971), ('特价机票', 633), ('查询', 625), ('预订', 449), ('便宜', 392), ('-', 369), ('打折', 327), ('特价', 268), ('到', 267), ('深圳', 265), ('北京', 256), ('航班', 243), ('广州', 240), ('的', 235), ('上海', 223), ('预定', 215), ('网站', 215), ('网', 180), ('飞机', 170)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80J8crWTKrIg"
      },
      "source": [
        "#### 二、Word to vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p98idB19B1ez",
        "outputId": "fe73c452-9f3a-4f4e-8352-877e0c68c37d"
      },
      "source": [
        "# 训练词向量\n",
        "from gensim.models import Word2Vec\n",
        "vec_size = 100\n",
        "\n",
        "w2v = Word2Vec(train_data, size = vec_size, min_count=1)\n",
        "w2v.wv['机票'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88fEfI6QcLse",
        "outputId": "860278c4-589f-4833-92b1-6c20fc2600b6"
      },
      "source": [
        "# 词编码\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(filters = \"\", split = \" \")\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "# 将句子转换为数字序列\n",
        "train_tokens = tokenizer.texts_to_sequences(train_data)\n",
        "\n",
        "max_len = max([len(t) for t in train_tokens])\n",
        "print(max_len)\n",
        "print(\"----------Tokenizer 结果-----------------\")\n",
        "for d, t in zip(train_data[:10], train_tokens[:10]):\n",
        "  print(d, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "----------Tokenizer 结果-----------------\n",
            "['1.5', '折', '机票'] [363, 123, 1]\n",
            "['10.1', '机票'] [240, 1]\n",
            "['10.1', '机票', '查询'] [240, 1, 4]\n",
            "['10.1', '特价机票'] [240, 3]\n",
            "['10', '月份', '特价机票'] [364, 146, 3]\n",
            "['17u', '.', 'cn'] [365, 366, 367]\n",
            "['1', '元', '机票'] [134, 368, 1]\n",
            "['1', '折', '机票', '查询'] [134, 123, 1, 4]\n",
            "['1', '折', '机票', '订购'] [134, 123, 1, 34]\n",
            "['1', '折', '机票网'] [134, 123, 59]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWgo7wkIaDSA"
      },
      "source": [
        "# 序列补全\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_pad = pad_sequences(train_tokens, maxlen=max_len,\n",
        "                            padding='pre', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udvUN9EETWzk"
      },
      "source": [
        "# 建立 index --> word 的映射，方便调用\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items())) # \n",
        "\n",
        "# 用word2vec结果初始化模型Embedding参数\n",
        "# embedding_matrix为一个 [num_words，embedding_dim] 的矩阵\n",
        "# 维度为 507 * 200\n",
        "num_words = W + 1\n",
        "embedding_dim = vec_size\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "for i in range(1, num_words):\n",
        "    embedding_matrix[i,:] = w2v.wv[reverse_word_map[i]]\n",
        "embedding_matrix = embedding_matrix.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8xI4jD1gjR2"
      },
      "source": [
        "#### 三、用keras搭建RNN模型并训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_GV02ERfJKd"
      },
      "source": [
        "# x: train_pad, y: y\n",
        "# 分割训练集和测试集\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
        "                                                    y,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQzR1yR0gs5V",
        "outputId": "b997e578-b5dd-448d-ba66-777fe30008e7"
      },
      "source": [
        "from keras.layers import Input, Embedding, Dense, SimpleRNN\n",
        "from keras.models import Model\n",
        "\n",
        "# 507 * 200\n",
        "hidden_size = 256\n",
        "\n",
        "# 定义RNN网络，layers表示中间RNN层数， trainable_embedding表示是否训练Embedding层\n",
        "# embedding层的初始权重为word2vec结果\n",
        "def RNN(layers = 2, trainable_embedding = False, embedding_init = [embedding_matrix]):\n",
        "  input = Input(shape = (max_len,))\n",
        "\n",
        "  x = Embedding(num_words, embedding_dim, mask_zero = True, weights=embedding_init,\n",
        "                      trainable = trainable_embedding)(input)\n",
        "  for _ in range(layers - 1):\n",
        "    x = SimpleRNN(hidden_size, return_sequences = True)(x)\n",
        "  x = SimpleRNN(hidden_size, return_sequences = False)(x)\n",
        "  x = Dense(1)(x)\n",
        "  model = Model(input, x)\n",
        "  return model\n",
        "\n",
        "model = RNN(1, False, [embedding_matrix])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 7)]               0         \n",
            "_________________________________________________________________\n",
            "embedding_17 (Embedding)     (None, 7, 100)            50700     \n",
            "_________________________________________________________________\n",
            "simple_rnn_14 (SimpleRNN)    (None, 256)               91392     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 142,349\n",
            "Trainable params: 91,649\n",
            "Non-trainable params: 50,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LZ_OQKcgoM5"
      },
      "source": [
        "import keras.backend as K\n",
        "import tensorflow_probability as tfp\n",
        "# 定义metric函数\n",
        "def MedSE(y_true, y_pred):\n",
        "  se = K.square(y_true - y_pred)\n",
        "  return tfp.stats.percentile(se, q=50.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvXq1bc4kNVi",
        "outputId": "2aa8f792-c003-42d3-960b-e251a7f603fc"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# 将效果最好的模型储存到hdf5文件\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='MedSE', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# 编译与训练\n",
        "model.compile(optimizer=Adam(lr=0.001), metrics=[MedSE], loss=\"mse\")\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=16, epochs=150, verbose=1, validation_data = (X_test, y_test), callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0336 - MedSE: 0.0215\n",
            "Epoch 00001: MedSE improved from inf to 0.02159, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0333 - MedSE: 0.0216 - val_loss: 0.0210 - val_MedSE: 0.0164\n",
            "Epoch 2/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0191 - MedSE: 0.0102\n",
            "Epoch 00002: MedSE improved from 0.02159 to 0.01023, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 0.0191 - MedSE: 0.0102 - val_loss: 0.0188 - val_MedSE: 0.0141\n",
            "Epoch 3/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0189 - MedSE: 0.0106\n",
            "Epoch 00003: MedSE did not improve from 0.01023\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 0.0189 - MedSE: 0.0105 - val_loss: 0.0168 - val_MedSE: 0.0105\n",
            "Epoch 4/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0173 - MedSE: 0.0098\n",
            "Epoch 00004: MedSE improved from 0.01023 to 0.00982, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0172 - MedSE: 0.0098 - val_loss: 0.0224 - val_MedSE: 0.0172\n",
            "Epoch 5/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0181 - MedSE: 0.0097\n",
            "Epoch 00005: MedSE improved from 0.00982 to 0.00975, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0181 - MedSE: 0.0098 - val_loss: 0.0181 - val_MedSE: 0.0072\n",
            "Epoch 6/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0184 - MedSE: 0.0103\n",
            "Epoch 00006: MedSE did not improve from 0.00975\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0183 - MedSE: 0.0103 - val_loss: 0.0171 - val_MedSE: 0.0077\n",
            "Epoch 7/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0183 - MedSE: 0.0101\n",
            "Epoch 00007: MedSE did not improve from 0.00975\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0182 - MedSE: 0.0101 - val_loss: 0.0181 - val_MedSE: 0.0116\n",
            "Epoch 8/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0176 - MedSE: 0.0097\n",
            "Epoch 00008: MedSE improved from 0.00975 to 0.00971, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 0.0176 - MedSE: 0.0097 - val_loss: 0.0192 - val_MedSE: 0.0141\n",
            "Epoch 9/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0168 - MedSE: 0.0096\n",
            "Epoch 00009: MedSE improved from 0.00971 to 0.00953, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0168 - MedSE: 0.0095 - val_loss: 0.0162 - val_MedSE: 0.0069\n",
            "Epoch 10/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0167 - MedSE: 0.0089\n",
            "Epoch 00010: MedSE improved from 0.00953 to 0.00890, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0167 - MedSE: 0.0089 - val_loss: 0.0174 - val_MedSE: 0.0103\n",
            "Epoch 11/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0169 - MedSE: 0.0094\n",
            "Epoch 00011: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0169 - MedSE: 0.0094 - val_loss: 0.0172 - val_MedSE: 0.0086\n",
            "Epoch 12/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0172 - MedSE: 0.0095\n",
            "Epoch 00012: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0172 - MedSE: 0.0094 - val_loss: 0.0175 - val_MedSE: 0.0096\n",
            "Epoch 13/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0177 - MedSE: 0.0096\n",
            "Epoch 00013: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0176 - MedSE: 0.0095 - val_loss: 0.0177 - val_MedSE: 0.0130\n",
            "Epoch 14/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0164 - MedSE: 0.0090\n",
            "Epoch 00014: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0165 - MedSE: 0.0091 - val_loss: 0.0157 - val_MedSE: 0.0095\n",
            "Epoch 15/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0169 - MedSE: 0.0098\n",
            "Epoch 00015: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0169 - MedSE: 0.0097 - val_loss: 0.0169 - val_MedSE: 0.0064\n",
            "Epoch 16/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0167 - MedSE: 0.0095\n",
            "Epoch 00016: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0166 - MedSE: 0.0094 - val_loss: 0.0189 - val_MedSE: 0.0062\n",
            "Epoch 17/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0171 - MedSE: 0.0090\n",
            "Epoch 00017: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0169 - MedSE: 0.0090 - val_loss: 0.0171 - val_MedSE: 0.0066\n",
            "Epoch 18/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0170 - MedSE: 0.0097\n",
            "Epoch 00018: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0170 - MedSE: 0.0097 - val_loss: 0.0157 - val_MedSE: 0.0089\n",
            "Epoch 19/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0169 - MedSE: 0.0093\n",
            "Epoch 00019: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0168 - MedSE: 0.0093 - val_loss: 0.0166 - val_MedSE: 0.0077\n",
            "Epoch 20/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0163 - MedSE: 0.0089\n",
            "Epoch 00020: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0162 - MedSE: 0.0092 - val_loss: 0.0162 - val_MedSE: 0.0072\n",
            "Epoch 21/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0162 - MedSE: 0.0092\n",
            "Epoch 00021: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0161 - MedSE: 0.0091 - val_loss: 0.0161 - val_MedSE: 0.0085\n",
            "Epoch 22/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0170 - MedSE: 0.0096\n",
            "Epoch 00022: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0170 - MedSE: 0.0095 - val_loss: 0.0178 - val_MedSE: 0.0059\n",
            "Epoch 23/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0164 - MedSE: 0.0091\n",
            "Epoch 00023: MedSE did not improve from 0.00890\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0166 - MedSE: 0.0090 - val_loss: 0.0167 - val_MedSE: 0.0099\n",
            "Epoch 24/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0159 - MedSE: 0.0087\n",
            "Epoch 00024: MedSE improved from 0.00890 to 0.00885, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0161 - MedSE: 0.0089 - val_loss: 0.0162 - val_MedSE: 0.0093\n",
            "Epoch 25/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0163 - MedSE: 0.0092\n",
            "Epoch 00025: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0164 - MedSE: 0.0094 - val_loss: 0.0164 - val_MedSE: 0.0095\n",
            "Epoch 26/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0162 - MedSE: 0.0092\n",
            "Epoch 00026: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0162 - MedSE: 0.0092 - val_loss: 0.0162 - val_MedSE: 0.0086\n",
            "Epoch 27/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0158 - MedSE: 0.0089\n",
            "Epoch 00027: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0160 - MedSE: 0.0091 - val_loss: 0.0160 - val_MedSE: 0.0105\n",
            "Epoch 28/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0163 - MedSE: 0.0092\n",
            "Epoch 00028: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0163 - MedSE: 0.0092 - val_loss: 0.0172 - val_MedSE: 0.0114\n",
            "Epoch 29/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0166 - MedSE: 0.0090\n",
            "Epoch 00029: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0166 - MedSE: 0.0090 - val_loss: 0.0158 - val_MedSE: 0.0093\n",
            "Epoch 30/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0162 - MedSE: 0.0089\n",
            "Epoch 00030: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0162 - MedSE: 0.0089 - val_loss: 0.0184 - val_MedSE: 0.0140\n",
            "Epoch 31/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0160 - MedSE: 0.0089\n",
            "Epoch 00031: MedSE did not improve from 0.00885\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0162 - MedSE: 0.0089 - val_loss: 0.0159 - val_MedSE: 0.0097\n",
            "Epoch 32/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0159 - MedSE: 0.0087\n",
            "Epoch 00032: MedSE improved from 0.00885 to 0.00870, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0158 - MedSE: 0.0087 - val_loss: 0.0156 - val_MedSE: 0.0098\n",
            "Epoch 33/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0157 - MedSE: 0.0083\n",
            "Epoch 00033: MedSE improved from 0.00870 to 0.00837, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0157 - MedSE: 0.0084 - val_loss: 0.0160 - val_MedSE: 0.0101\n",
            "Epoch 34/150\n",
            "146/152 [===========================>..] - ETA: 0s - loss: 0.0158 - MedSE: 0.0085\n",
            "Epoch 00034: MedSE did not improve from 0.00837\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0158 - MedSE: 0.0085 - val_loss: 0.0157 - val_MedSE: 0.0094\n",
            "Epoch 35/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0155 - MedSE: 0.0083\n",
            "Epoch 00035: MedSE improved from 0.00837 to 0.00834, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0155 - MedSE: 0.0083 - val_loss: 0.0149 - val_MedSE: 0.0082\n",
            "Epoch 36/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0156 - MedSE: 0.0087\n",
            "Epoch 00036: MedSE did not improve from 0.00834\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0155 - MedSE: 0.0086 - val_loss: 0.0169 - val_MedSE: 0.0072\n",
            "Epoch 37/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0155 - MedSE: 0.0079\n",
            "Epoch 00037: MedSE improved from 0.00834 to 0.00792, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0154 - MedSE: 0.0079 - val_loss: 0.0154 - val_MedSE: 0.0085\n",
            "Epoch 38/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0157 - MedSE: 0.0087\n",
            "Epoch 00038: MedSE did not improve from 0.00792\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0156 - MedSE: 0.0087 - val_loss: 0.0154 - val_MedSE: 0.0069\n",
            "Epoch 39/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0152 - MedSE: 0.0078\n",
            "Epoch 00039: MedSE improved from 0.00792 to 0.00771, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0151 - MedSE: 0.0077 - val_loss: 0.0147 - val_MedSE: 0.0077\n",
            "Epoch 40/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0152 - MedSE: 0.0080\n",
            "Epoch 00040: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0152 - MedSE: 0.0081 - val_loss: 0.0154 - val_MedSE: 0.0092\n",
            "Epoch 41/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0151 - MedSE: 0.0079\n",
            "Epoch 00041: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0151 - MedSE: 0.0081 - val_loss: 0.0148 - val_MedSE: 0.0078\n",
            "Epoch 42/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0156 - MedSE: 0.0082\n",
            "Epoch 00042: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0156 - MedSE: 0.0082 - val_loss: 0.0147 - val_MedSE: 0.0087\n",
            "Epoch 43/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0152 - MedSE: 0.0080\n",
            "Epoch 00043: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0152 - MedSE: 0.0080 - val_loss: 0.0143 - val_MedSE: 0.0073\n",
            "Epoch 44/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0151 - MedSE: 0.0081\n",
            "Epoch 00044: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0151 - MedSE: 0.0081 - val_loss: 0.0148 - val_MedSE: 0.0082\n",
            "Epoch 45/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0151 - MedSE: 0.0081\n",
            "Epoch 00045: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0152 - MedSE: 0.0081 - val_loss: 0.0146 - val_MedSE: 0.0079\n",
            "Epoch 46/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0154 - MedSE: 0.0081\n",
            "Epoch 00046: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0153 - MedSE: 0.0081 - val_loss: 0.0146 - val_MedSE: 0.0075\n",
            "Epoch 47/150\n",
            "146/152 [===========================>..] - ETA: 0s - loss: 0.0153 - MedSE: 0.0082\n",
            "Epoch 00047: MedSE did not improve from 0.00771\n",
            "152/152 [==============================] - 2s 11ms/step - loss: 0.0152 - MedSE: 0.0082 - val_loss: 0.0146 - val_MedSE: 0.0076\n",
            "Epoch 48/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0149 - MedSE: 0.0077\n",
            "Epoch 00048: MedSE improved from 0.00771 to 0.00770, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0151 - MedSE: 0.0077 - val_loss: 0.0142 - val_MedSE: 0.0066\n",
            "Epoch 49/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0151 - MedSE: 0.0084\n",
            "Epoch 00049: MedSE did not improve from 0.00770\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0151 - MedSE: 0.0084 - val_loss: 0.0144 - val_MedSE: 0.0072\n",
            "Epoch 50/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0150 - MedSE: 0.0083\n",
            "Epoch 00050: MedSE did not improve from 0.00770\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0149 - MedSE: 0.0082 - val_loss: 0.0148 - val_MedSE: 0.0080\n",
            "Epoch 51/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0149 - MedSE: 0.0078\n",
            "Epoch 00051: MedSE did not improve from 0.00770\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0148 - MedSE: 0.0080 - val_loss: 0.0142 - val_MedSE: 0.0078\n",
            "Epoch 52/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0076\n",
            "Epoch 00052: MedSE improved from 0.00770 to 0.00760, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0146 - MedSE: 0.0076 - val_loss: 0.0141 - val_MedSE: 0.0069\n",
            "Epoch 53/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0148 - MedSE: 0.0076\n",
            "Epoch 00053: MedSE did not improve from 0.00760\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0148 - MedSE: 0.0077 - val_loss: 0.0142 - val_MedSE: 0.0061\n",
            "Epoch 54/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0148 - MedSE: 0.0079\n",
            "Epoch 00054: MedSE did not improve from 0.00760\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0148 - MedSE: 0.0080 - val_loss: 0.0142 - val_MedSE: 0.0068\n",
            "Epoch 55/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0149 - MedSE: 0.0076\n",
            "Epoch 00055: MedSE did not improve from 0.00760\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0149 - MedSE: 0.0077 - val_loss: 0.0152 - val_MedSE: 0.0087\n",
            "Epoch 56/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0150 - MedSE: 0.0076\n",
            "Epoch 00056: MedSE did not improve from 0.00760\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0150 - MedSE: 0.0077 - val_loss: 0.0138 - val_MedSE: 0.0070\n",
            "Epoch 57/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0076\n",
            "Epoch 00057: MedSE improved from 0.00760 to 0.00757, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0146 - MedSE: 0.0076 - val_loss: 0.0147 - val_MedSE: 0.0072\n",
            "Epoch 58/150\n",
            "146/152 [===========================>..] - ETA: 0s - loss: 0.0148 - MedSE: 0.0077\n",
            "Epoch 00058: MedSE did not improve from 0.00757\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0147 - MedSE: 0.0078 - val_loss: 0.0145 - val_MedSE: 0.0073\n",
            "Epoch 59/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0148 - MedSE: 0.0076\n",
            "Epoch 00059: MedSE improved from 0.00757 to 0.00753, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0148 - MedSE: 0.0075 - val_loss: 0.0151 - val_MedSE: 0.0087\n",
            "Epoch 60/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0073\n",
            "Epoch 00060: MedSE improved from 0.00753 to 0.00730, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0147 - MedSE: 0.0073 - val_loss: 0.0142 - val_MedSE: 0.0078\n",
            "Epoch 61/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0073\n",
            "Epoch 00061: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0147 - MedSE: 0.0074 - val_loss: 0.0139 - val_MedSE: 0.0068\n",
            "Epoch 62/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0147 - MedSE: 0.0076\n",
            "Epoch 00062: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0147 - MedSE: 0.0077 - val_loss: 0.0137 - val_MedSE: 0.0063\n",
            "Epoch 63/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0145 - MedSE: 0.0074\n",
            "Epoch 00063: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0145 - MedSE: 0.0075 - val_loss: 0.0138 - val_MedSE: 0.0067\n",
            "Epoch 64/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0145 - MedSE: 0.0074\n",
            "Epoch 00064: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0145 - MedSE: 0.0074 - val_loss: 0.0140 - val_MedSE: 0.0069\n",
            "Epoch 65/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0074\n",
            "Epoch 00065: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0146 - MedSE: 0.0075 - val_loss: 0.0139 - val_MedSE: 0.0062\n",
            "Epoch 66/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0077\n",
            "Epoch 00066: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0146 - MedSE: 0.0077 - val_loss: 0.0145 - val_MedSE: 0.0083\n",
            "Epoch 67/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0145 - MedSE: 0.0074\n",
            "Epoch 00067: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0145 - MedSE: 0.0075 - val_loss: 0.0143 - val_MedSE: 0.0064\n",
            "Epoch 68/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0075\n",
            "Epoch 00068: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0146 - MedSE: 0.0075 - val_loss: 0.0142 - val_MedSE: 0.0079\n",
            "Epoch 69/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0145 - MedSE: 0.0074\n",
            "Epoch 00069: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0145 - MedSE: 0.0074 - val_loss: 0.0145 - val_MedSE: 0.0090\n",
            "Epoch 70/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0147 - MedSE: 0.0077\n",
            "Epoch 00070: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0145 - MedSE: 0.0076 - val_loss: 0.0143 - val_MedSE: 0.0067\n",
            "Epoch 71/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0074\n",
            "Epoch 00071: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0146 - MedSE: 0.0075 - val_loss: 0.0138 - val_MedSE: 0.0073\n",
            "Epoch 72/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0143 - MedSE: 0.0074\n",
            "Epoch 00072: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0143 - MedSE: 0.0075 - val_loss: 0.0141 - val_MedSE: 0.0062\n",
            "Epoch 73/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0144 - MedSE: 0.0075\n",
            "Epoch 00073: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0144 - MedSE: 0.0075 - val_loss: 0.0142 - val_MedSE: 0.0069\n",
            "Epoch 74/150\n",
            "146/152 [===========================>..] - ETA: 0s - loss: 0.0143 - MedSE: 0.0073\n",
            "Epoch 00074: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0144 - MedSE: 0.0076 - val_loss: 0.0139 - val_MedSE: 0.0073\n",
            "Epoch 75/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0148 - MedSE: 0.0077\n",
            "Epoch 00075: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0148 - MedSE: 0.0076 - val_loss: 0.0141 - val_MedSE: 0.0081\n",
            "Epoch 76/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0141 - MedSE: 0.0076\n",
            "Epoch 00076: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0145 - MedSE: 0.0076 - val_loss: 0.0143 - val_MedSE: 0.0087\n",
            "Epoch 77/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0141 - MedSE: 0.0074\n",
            "Epoch 00077: MedSE did not improve from 0.00730\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0142 - MedSE: 0.0074 - val_loss: 0.0136 - val_MedSE: 0.0064\n",
            "Epoch 78/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0143 - MedSE: 0.0072\n",
            "Epoch 00078: MedSE improved from 0.00730 to 0.00712, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0142 - MedSE: 0.0071 - val_loss: 0.0145 - val_MedSE: 0.0065\n",
            "Epoch 79/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0141 - MedSE: 0.0073\n",
            "Epoch 00079: MedSE did not improve from 0.00712\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0141 - MedSE: 0.0073 - val_loss: 0.0147 - val_MedSE: 0.0065\n",
            "Epoch 80/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0146 - MedSE: 0.0075\n",
            "Epoch 00080: MedSE did not improve from 0.00712\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0146 - MedSE: 0.0075 - val_loss: 0.0149 - val_MedSE: 0.0085\n",
            "Epoch 81/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0143 - MedSE: 0.0075\n",
            "Epoch 00081: MedSE did not improve from 0.00712\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0144 - MedSE: 0.0076 - val_loss: 0.0136 - val_MedSE: 0.0069\n",
            "Epoch 82/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0071\n",
            "Epoch 00082: MedSE improved from 0.00712 to 0.00704, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0142 - MedSE: 0.0070 - val_loss: 0.0140 - val_MedSE: 0.0073\n",
            "Epoch 83/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0144 - MedSE: 0.0076\n",
            "Epoch 00083: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0143 - MedSE: 0.0076 - val_loss: 0.0136 - val_MedSE: 0.0063\n",
            "Epoch 84/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0144 - MedSE: 0.0070\n",
            "Epoch 00084: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0143 - MedSE: 0.0071 - val_loss: 0.0137 - val_MedSE: 0.0078\n",
            "Epoch 85/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0070\n",
            "Epoch 00085: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0140 - MedSE: 0.0071 - val_loss: 0.0142 - val_MedSE: 0.0087\n",
            "Epoch 86/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0072\n",
            "Epoch 00086: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0141 - MedSE: 0.0073 - val_loss: 0.0140 - val_MedSE: 0.0076\n",
            "Epoch 87/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0074\n",
            "Epoch 00087: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0140 - MedSE: 0.0073 - val_loss: 0.0137 - val_MedSE: 0.0066\n",
            "Epoch 88/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0071\n",
            "Epoch 00088: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0142 - MedSE: 0.0071 - val_loss: 0.0140 - val_MedSE: 0.0066\n",
            "Epoch 89/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0074\n",
            "Epoch 00089: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0142 - MedSE: 0.0074 - val_loss: 0.0135 - val_MedSE: 0.0063\n",
            "Epoch 90/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0074\n",
            "Epoch 00090: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0141 - MedSE: 0.0074 - val_loss: 0.0132 - val_MedSE: 0.0068\n",
            "Epoch 91/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0144 - MedSE: 0.0072\n",
            "Epoch 00091: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0143 - MedSE: 0.0072 - val_loss: 0.0138 - val_MedSE: 0.0060\n",
            "Epoch 92/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0138 - MedSE: 0.0071\n",
            "Epoch 00092: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0138 - MedSE: 0.0071 - val_loss: 0.0133 - val_MedSE: 0.0066\n",
            "Epoch 93/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0072\n",
            "Epoch 00093: MedSE did not improve from 0.00704\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0140 - MedSE: 0.0072 - val_loss: 0.0133 - val_MedSE: 0.0067\n",
            "Epoch 94/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0069\n",
            "Epoch 00094: MedSE improved from 0.00704 to 0.00689, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0069 - val_loss: 0.0134 - val_MedSE: 0.0071\n",
            "Epoch 95/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0068\n",
            "Epoch 00095: MedSE improved from 0.00689 to 0.00675, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0067 - val_loss: 0.0141 - val_MedSE: 0.0075\n",
            "Epoch 96/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0071\n",
            "Epoch 00096: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0071 - val_loss: 0.0140 - val_MedSE: 0.0085\n",
            "Epoch 97/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0072\n",
            "Epoch 00097: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0071 - val_loss: 0.0137 - val_MedSE: 0.0062\n",
            "Epoch 98/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0066\n",
            "Epoch 00098: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0140 - MedSE: 0.0068 - val_loss: 0.0141 - val_MedSE: 0.0081\n",
            "Epoch 99/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0074\n",
            "Epoch 00099: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0140 - MedSE: 0.0075 - val_loss: 0.0139 - val_MedSE: 0.0079\n",
            "Epoch 100/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0139 - MedSE: 0.0072\n",
            "Epoch 00100: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0138 - MedSE: 0.0072 - val_loss: 0.0138 - val_MedSE: 0.0060\n",
            "Epoch 101/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0141 - MedSE: 0.0071\n",
            "Epoch 00101: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0140 - MedSE: 0.0072 - val_loss: 0.0139 - val_MedSE: 0.0071\n",
            "Epoch 102/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0067\n",
            "Epoch 00102: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0068 - val_loss: 0.0140 - val_MedSE: 0.0064\n",
            "Epoch 103/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0139 - MedSE: 0.0072\n",
            "Epoch 00103: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0139 - MedSE: 0.0071 - val_loss: 0.0137 - val_MedSE: 0.0058\n",
            "Epoch 104/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0069\n",
            "Epoch 00104: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0069 - val_loss: 0.0139 - val_MedSE: 0.0060\n",
            "Epoch 105/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0141 - MedSE: 0.0075\n",
            "Epoch 00105: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0141 - MedSE: 0.0075 - val_loss: 0.0147 - val_MedSE: 0.0070\n",
            "Epoch 106/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0139 - MedSE: 0.0071\n",
            "Epoch 00106: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0071 - val_loss: 0.0143 - val_MedSE: 0.0073\n",
            "Epoch 107/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0068\n",
            "Epoch 00107: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0136 - MedSE: 0.0069 - val_loss: 0.0137 - val_MedSE: 0.0063\n",
            "Epoch 108/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0140 - MedSE: 0.0072\n",
            "Epoch 00108: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0140 - MedSE: 0.0074 - val_loss: 0.0131 - val_MedSE: 0.0062\n",
            "Epoch 109/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0069\n",
            "Epoch 00109: MedSE did not improve from 0.00675\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0069 - val_loss: 0.0137 - val_MedSE: 0.0075\n",
            "Epoch 110/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0067\n",
            "Epoch 00110: MedSE improved from 0.00675 to 0.00671, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0067 - val_loss: 0.0143 - val_MedSE: 0.0060\n",
            "Epoch 111/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0071\n",
            "Epoch 00111: MedSE did not improve from 0.00671\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0071 - val_loss: 0.0134 - val_MedSE: 0.0064\n",
            "Epoch 112/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0134 - MedSE: 0.0069\n",
            "Epoch 00112: MedSE did not improve from 0.00671\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0069 - val_loss: 0.0133 - val_MedSE: 0.0067\n",
            "Epoch 113/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0069\n",
            "Epoch 00113: MedSE did not improve from 0.00671\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0138 - MedSE: 0.0069 - val_loss: 0.0137 - val_MedSE: 0.0074\n",
            "Epoch 114/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0137 - MedSE: 0.0070\n",
            "Epoch 00114: MedSE did not improve from 0.00671\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0137 - MedSE: 0.0070 - val_loss: 0.0133 - val_MedSE: 0.0060\n",
            "Epoch 115/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0067\n",
            "Epoch 00115: MedSE improved from 0.00671 to 0.00665, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0067 - val_loss: 0.0139 - val_MedSE: 0.0062\n",
            "Epoch 116/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0068\n",
            "Epoch 00116: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0071 - val_loss: 0.0138 - val_MedSE: 0.0061\n",
            "Epoch 117/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0070\n",
            "Epoch 00117: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0135 - MedSE: 0.0070 - val_loss: 0.0132 - val_MedSE: 0.0064\n",
            "Epoch 118/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0139 - MedSE: 0.0068\n",
            "Epoch 00118: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0069 - val_loss: 0.0135 - val_MedSE: 0.0075\n",
            "Epoch 119/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0073\n",
            "Epoch 00119: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0138 - MedSE: 0.0073 - val_loss: 0.0138 - val_MedSE: 0.0070\n",
            "Epoch 120/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0066\n",
            "Epoch 00120: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0136 - MedSE: 0.0067 - val_loss: 0.0157 - val_MedSE: 0.0109\n",
            "Epoch 121/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0139 - MedSE: 0.0069\n",
            "Epoch 00121: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0139 - MedSE: 0.0069 - val_loss: 0.0136 - val_MedSE: 0.0071\n",
            "Epoch 122/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0068\n",
            "Epoch 00122: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0068 - val_loss: 0.0155 - val_MedSE: 0.0069\n",
            "Epoch 123/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0069\n",
            "Epoch 00123: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0136 - MedSE: 0.0069 - val_loss: 0.0135 - val_MedSE: 0.0067\n",
            "Epoch 124/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0068\n",
            "Epoch 00124: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0069 - val_loss: 0.0135 - val_MedSE: 0.0064\n",
            "Epoch 125/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0142 - MedSE: 0.0071\n",
            "Epoch 00125: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0141 - MedSE: 0.0071 - val_loss: 0.0131 - val_MedSE: 0.0063\n",
            "Epoch 126/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0135 - MedSE: 0.0068\n",
            "Epoch 00126: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0136 - MedSE: 0.0070 - val_loss: 0.0136 - val_MedSE: 0.0079\n",
            "Epoch 127/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0069\n",
            "Epoch 00127: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0135 - MedSE: 0.0070 - val_loss: 0.0143 - val_MedSE: 0.0078\n",
            "Epoch 128/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0069\n",
            "Epoch 00128: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0138 - MedSE: 0.0070 - val_loss: 0.0132 - val_MedSE: 0.0069\n",
            "Epoch 129/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0070\n",
            "Epoch 00129: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0135 - MedSE: 0.0071 - val_loss: 0.0137 - val_MedSE: 0.0066\n",
            "Epoch 130/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0072\n",
            "Epoch 00130: MedSE did not improve from 0.00665\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0135 - MedSE: 0.0074 - val_loss: 0.0139 - val_MedSE: 0.0078\n",
            "Epoch 131/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0135 - MedSE: 0.0065\n",
            "Epoch 00131: MedSE improved from 0.00665 to 0.00658, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0134 - MedSE: 0.0066 - val_loss: 0.0155 - val_MedSE: 0.0096\n",
            "Epoch 132/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0136 - MedSE: 0.0069\n",
            "Epoch 00132: MedSE did not improve from 0.00658\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0136 - MedSE: 0.0071 - val_loss: 0.0134 - val_MedSE: 0.0071\n",
            "Epoch 133/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0136 - MedSE: 0.0069\n",
            "Epoch 00133: MedSE did not improve from 0.00658\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0136 - MedSE: 0.0069 - val_loss: 0.0131 - val_MedSE: 0.0061\n",
            "Epoch 134/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0132 - MedSE: 0.0064\n",
            "Epoch 00134: MedSE improved from 0.00658 to 0.00635, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0132 - MedSE: 0.0064 - val_loss: 0.0133 - val_MedSE: 0.0064\n",
            "Epoch 135/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0135 - MedSE: 0.0068\n",
            "Epoch 00135: MedSE did not improve from 0.00635\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0135 - MedSE: 0.0068 - val_loss: 0.0144 - val_MedSE: 0.0077\n",
            "Epoch 136/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0067\n",
            "Epoch 00136: MedSE did not improve from 0.00635\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0138 - MedSE: 0.0067 - val_loss: 0.0134 - val_MedSE: 0.0065\n",
            "Epoch 137/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0137 - MedSE: 0.0069\n",
            "Epoch 00137: MedSE did not improve from 0.00635\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0136 - MedSE: 0.0069 - val_loss: 0.0138 - val_MedSE: 0.0082\n",
            "Epoch 138/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0131 - MedSE: 0.0063\n",
            "Epoch 00138: MedSE improved from 0.00635 to 0.00621, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0131 - MedSE: 0.0062 - val_loss: 0.0131 - val_MedSE: 0.0063\n",
            "Epoch 139/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0134 - MedSE: 0.0067\n",
            "Epoch 00139: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0135 - MedSE: 0.0069 - val_loss: 0.0136 - val_MedSE: 0.0062\n",
            "Epoch 140/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0135 - MedSE: 0.0066\n",
            "Epoch 00140: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0136 - MedSE: 0.0068 - val_loss: 0.0135 - val_MedSE: 0.0071\n",
            "Epoch 141/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0135 - MedSE: 0.0066\n",
            "Epoch 00141: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 14ms/step - loss: 0.0135 - MedSE: 0.0065 - val_loss: 0.0142 - val_MedSE: 0.0086\n",
            "Epoch 142/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0138 - MedSE: 0.0071\n",
            "Epoch 00142: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0137 - MedSE: 0.0070 - val_loss: 0.0141 - val_MedSE: 0.0082\n",
            "Epoch 143/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0133 - MedSE: 0.0069\n",
            "Epoch 00143: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0133 - MedSE: 0.0069 - val_loss: 0.0131 - val_MedSE: 0.0066\n",
            "Epoch 144/150\n",
            "150/152 [============================>.] - ETA: 0s - loss: 0.0133 - MedSE: 0.0066\n",
            "Epoch 00144: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0133 - MedSE: 0.0067 - val_loss: 0.0133 - val_MedSE: 0.0070\n",
            "Epoch 145/150\n",
            "152/152 [==============================] - ETA: 0s - loss: 0.0133 - MedSE: 0.0066\n",
            "Epoch 00145: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0133 - MedSE: 0.0066 - val_loss: 0.0139 - val_MedSE: 0.0080\n",
            "Epoch 146/150\n",
            "148/152 [============================>.] - ETA: 0s - loss: 0.0135 - MedSE: 0.0066\n",
            "Epoch 00146: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 12ms/step - loss: 0.0135 - MedSE: 0.0067 - val_loss: 0.0130 - val_MedSE: 0.0065\n",
            "Epoch 147/150\n",
            "147/152 [============================>.] - ETA: 0s - loss: 0.0131 - MedSE: 0.0063\n",
            "Epoch 00147: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0130 - MedSE: 0.0063 - val_loss: 0.0138 - val_MedSE: 0.0066\n",
            "Epoch 148/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0133 - MedSE: 0.0068\n",
            "Epoch 00148: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0134 - MedSE: 0.0068 - val_loss: 0.0130 - val_MedSE: 0.0059\n",
            "Epoch 149/150\n",
            "151/152 [============================>.] - ETA: 0s - loss: 0.0131 - MedSE: 0.0067\n",
            "Epoch 00149: MedSE did not improve from 0.00621\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0131 - MedSE: 0.0067 - val_loss: 0.0133 - val_MedSE: 0.0066\n",
            "Epoch 150/150\n",
            "149/152 [============================>.] - ETA: 0s - loss: 0.0130 - MedSE: 0.0061\n",
            "Epoch 00150: MedSE improved from 0.00621 to 0.00605, saving model to weights.best.hdf5\n",
            "152/152 [==============================] - 2s 13ms/step - loss: 0.0130 - MedSE: 0.0061 - val_loss: 0.0139 - val_MedSE: 0.0074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "9cU9LBuul4n3",
        "outputId": "3c4725fc-7300-4fc0-c5d6-7b953352b6d6"
      },
      "source": [
        "plt.plot(history.history['loss'][:100])\n",
        "plt.plot(history.history['val_loss'][:100])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9Gvya-JggGhY",
        "outputId": "5827eee1-1139-4ff0-9893-2597dd78866b"
      },
      "source": [
        "# Medloss 箱线图\n",
        "plt.boxplot(list(history.history['MedSE']))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}