{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "hw6-2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF474CUhngjM"
      },
      "source": [
        "### Build ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy-OXq1sngjM",
        "outputId": "fa56a857-bbb6-40bb-949e-8e9539248ad8"
      },
      "source": [
        "# refer to keras.applications.resnet\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from tensorflow.keras import backend, layers, models\n",
        "import keras.utils as keras_utils\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.applications.imagenet_utils import decode_predictions,preprocess_input\n",
        "\n",
        "'''\n",
        "WEIGHTS_PATH : https://github.com/fchollet/deep-learning-models/\n",
        "                releases/download/v0.2/\n",
        "                resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP : https://github.com/fchollet/deep-learning-models/\n",
        "                       releases/download/v0.2/'\n",
        "                       resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "'''\n",
        "\n",
        "global backend, layers, models, keras_utils\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor,\n",
        "               kernel_size,\n",
        "               filters,\n",
        "               stage,\n",
        "               block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "        strides: Strides for the first conv layer in the block.\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3,\n",
        "    the first conv layer at main path is with strides=(2, 2)\n",
        "    And the shortcut should have strides=(2, 2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if backend.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1),\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=100,\n",
        "             **kwargs):\n",
        "\n",
        "    global backend, layers, models, keras_utils\n",
        "    \n",
        "    # the input of ImageNet pre-train model sizes 224 * 224 * 224\n",
        "    # Upsample images in Cifar100 (32, 32, 3) to (256, 256, 3) first.\n",
        "    # Set input shape to (256,256,3)\n",
        "    img_input = layers.Input(shape=(256,256,3))\n",
        "\n",
        "    # the axis of color（channel）is 3\n",
        "    bn_axis = 3\n",
        "\n",
        "    # connect the blocks\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "\n",
        "    inputs = img_input\n",
        "\n",
        "    # Create model.\n",
        "    base_model = models.Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # Load weights.\n",
        "    weights_path = keras_utils.get_file(\n",
        "            'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "            WEIGHTS_PATH_NO_TOP,\n",
        "            cache_subdir='models',\n",
        "            md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "    base_model.load_weights(weights_path)\n",
        "    for layer in base_model.layers:\n",
        "        if isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False    \n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "    x = layers.UpSampling2D()(input_layer)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    x = base_model(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(.25)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Dense(classes, activation='softmax', name='fc_classes')(x)\n",
        "    # this is the model we will train\n",
        "    # Create another model with softmax\n",
        "    model = models.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJw1yE5NngjO"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNcstJfngjO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# data augmentation function\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-kwlitfngjO"
      },
      "source": [
        "img_rows, img_cols = 32, 32 # Resolution of original inputs\n",
        "channel = 3\n",
        "num_classes = 100 \n",
        "batch_size = 16 \n",
        "nb_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8GLgnrAngjO",
        "outputId": "c8c6ad58-32c8-4aff-c94d-632aeb5a6653"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100 \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(X_train, Y_train), (X_valid, Y_valid) = cifar100.load_data()\n",
        "nb_train_samples = len(X_train)\n",
        "nb_valid_samples = len(X_valid)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "#Pre-process the data\n",
        "X_train = preprocess_input(X_train)\n",
        "X_valid = preprocess_input(X_valid)\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "datagen.fit(X_train)\n",
        "\n",
        "Y_train = keras_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
        "Y_valid = keras_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dZ1AcsbengjO",
        "outputId": "a9a9f231-c2d1-4a3f-8e99-607e887d24da"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "# Model parallel\n",
        "# But I am not sure it turns out successful\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    model = ResNet50(classes = num_classes, input_shape=(img_rows, img_cols, channel))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "t=time.time()\n",
        "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
        "                                  batch_size=64),\n",
        "                                  steps_per_epoch=X_train.shape[0] // 64,\n",
        "                                  epochs=100,\n",
        "                                  validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n",
            "Number of devices: 5\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From <ipython-input-7-866a5a9c0240>:22: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /home/wxr/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
            "INFO:tensorflow:batch_all_reduce: 112 all-reduces with algorithm = nccl, num_packs = 1\n",
            "INFO:tensorflow:batch_all_reduce: 112 all-reduces with algorithm = nccl, num_packs = 1\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 2.4297 - accuracy: 0.3949 - val_loss: 1.1335 - val_accuracy: 0.6673\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.5224 - accuracy: 0.5783 - val_loss: 0.9656 - val_accuracy: 0.7143\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.3226 - accuracy: 0.6263 - val_loss: 0.8808 - val_accuracy: 0.7385\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.2354 - accuracy: 0.6499 - val_loss: 0.8532 - val_accuracy: 0.7408\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.1681 - accuracy: 0.6670 - val_loss: 0.7758 - val_accuracy: 0.7664\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.1146 - accuracy: 0.6804 - val_loss: 0.7627 - val_accuracy: 0.7761\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.0893 - accuracy: 0.6861 - val_loss: 0.7424 - val_accuracy: 0.7779\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 1.0511 - accuracy: 0.6974 - val_loss: 0.7484 - val_accuracy: 0.7816\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 1.0186 - accuracy: 0.7041 - val_loss: 0.7637 - val_accuracy: 0.7750\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.9777 - accuracy: 0.7158 - val_loss: 0.7064 - val_accuracy: 0.7940\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.9603 - accuracy: 0.7218 - val_loss: 0.7522 - val_accuracy: 0.7807\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.9386 - accuracy: 0.7263 - val_loss: 0.7135 - val_accuracy: 0.7907\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.9145 - accuracy: 0.7333 - val_loss: 0.7075 - val_accuracy: 0.7932\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 77s 98ms/step - loss: 0.8794 - accuracy: 0.7413 - val_loss: 0.7158 - val_accuracy: 0.7925\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.8801 - accuracy: 0.7406 - val_loss: 0.7283 - val_accuracy: 0.7863\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.8566 - accuracy: 0.7479 - val_loss: 0.6934 - val_accuracy: 0.8018\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.8300 - accuracy: 0.7544 - val_loss: 0.6826 - val_accuracy: 0.8039\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.8296 - accuracy: 0.7564 - val_loss: 0.6876 - val_accuracy: 0.8045\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.8130 - accuracy: 0.7607 - val_loss: 0.7128 - val_accuracy: 0.7979\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7967 - accuracy: 0.7661 - val_loss: 0.6885 - val_accuracy: 0.8027\n",
            "Epoch 21/100\n",
            "767/781 [============================>.] - ETA: 1s - loss: 0.7774 - accuracy: 0.7695"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 78s 99ms/step - loss: 0.7546 - accuracy: 0.7778 - val_loss: 0.7122 - val_accuracy: 0.8027\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 77s 98ms/step - loss: 0.7365 - accuracy: 0.7796 - val_loss: 0.6816 - val_accuracy: 0.8039\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7332 - accuracy: 0.7819 - val_loss: 0.7057 - val_accuracy: 0.8030\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.7148 - accuracy: 0.7870 - val_loss: 0.6937 - val_accuracy: 0.8051\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7179 - accuracy: 0.7871 - val_loss: 0.6919 - val_accuracy: 0.8029\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7065 - accuracy: 0.7886 - val_loss: 0.6916 - val_accuracy: 0.8050\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.6973 - accuracy: 0.7905 - val_loss: 0.6886 - val_accuracy: 0.8074\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7070 - accuracy: 0.7888 - val_loss: 0.6884 - val_accuracy: 0.8031\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.7003 - accuracy: 0.7893 - val_loss: 0.7062 - val_accuracy: 0.8057\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.6946 - accuracy: 0.7924 - val_loss: 0.6997 - val_accuracy: 0.8049\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.6780 - accuracy: 0.7985 - val_loss: 0.6989 - val_accuracy: 0.8085\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.6619 - accuracy: 0.8017 - val_loss: 0.6866 - val_accuracy: 0.8090\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.6584 - accuracy: 0.8029 - val_loss: 0.7076 - val_accuracy: 0.8031\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.6609 - accuracy: 0.8006 - val_loss: 0.7003 - val_accuracy: 0.8086\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 78s 100ms/step - loss: 0.6516 - accuracy: 0.8045 - val_loss: 0.7135 - val_accuracy: 0.8073\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.6359 - accuracy: 0.8097 - val_loss: 0.7012 - val_accuracy: 0.8082\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.6300 - accuracy: 0.8095 - val_loss: 0.6865 - val_accuracy: 0.8104\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5255 - accuracy: 0.8395 - val_loss: 0.7075 - val_accuracy: 0.8160\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5220 - accuracy: 0.8410 - val_loss: 0.7073 - val_accuracy: 0.8154\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 77s 98ms/step - loss: 0.5203 - accuracy: 0.8425 - val_loss: 0.7226 - val_accuracy: 0.8140\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5161 - accuracy: 0.8427 - val_loss: 0.7148 - val_accuracy: 0.8119\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5222 - accuracy: 0.8424 - val_loss: 0.7173 - val_accuracy: 0.8152\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5243 - accuracy: 0.8418 - val_loss: 0.7167 - val_accuracy: 0.8077\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5188 - accuracy: 0.8427 - val_loss: 0.7129 - val_accuracy: 0.8119\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5159 - accuracy: 0.8441 - val_loss: 0.7176 - val_accuracy: 0.8143\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.5059 - accuracy: 0.8470 - val_loss: 0.7116 - val_accuracy: 0.8145\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5023 - accuracy: 0.8448 - val_loss: 0.7178 - val_accuracy: 0.8124\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4922 - accuracy: 0.8487 - val_loss: 0.7291 - val_accuracy: 0.8140\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5081 - accuracy: 0.8456 - val_loss: 0.7341 - val_accuracy: 0.8086\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5082 - accuracy: 0.8444 - val_loss: 0.7221 - val_accuracy: 0.8144\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5120 - accuracy: 0.8440 - val_loss: 0.7437 - val_accuracy: 0.8131\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5053 - accuracy: 0.8455 - val_loss: 0.7421 - val_accuracy: 0.8119\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.5179 - accuracy: 0.8424 - val_loss: 0.7140 - val_accuracy: 0.8142\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4980 - accuracy: 0.8485 - val_loss: 0.7126 - val_accuracy: 0.8171\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4943 - accuracy: 0.8491 - val_loss: 0.7281 - val_accuracy: 0.8106\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4901 - accuracy: 0.8521 - val_loss: 0.7353 - val_accuracy: 0.8140\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.5007 - accuracy: 0.8487 - val_loss: 0.7311 - val_accuracy: 0.8126\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4896 - accuracy: 0.8517 - val_loss: 0.7198 - val_accuracy: 0.8152\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4902 - accuracy: 0.8517 - val_loss: 0.7167 - val_accuracy: 0.8167\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4849 - accuracy: 0.8526 - val_loss: 0.7215 - val_accuracy: 0.8159\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4894 - accuracy: 0.8495 - val_loss: 0.7301 - val_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.4865 - accuracy: 0.8545 - val_loss: 0.7321 - val_accuracy: 0.8160\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4714 - accuracy: 0.8570 - val_loss: 0.7394 - val_accuracy: 0.8131\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.4666 - accuracy: 0.8572 - val_loss: 0.7287 - val_accuracy: 0.8192\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4829 - accuracy: 0.8527 - val_loss: 0.7361 - val_accuracy: 0.8161\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4622 - accuracy: 0.8592 - val_loss: 0.7125 - val_accuracy: 0.8205\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4777 - accuracy: 0.8550 - val_loss: 0.7216 - val_accuracy: 0.8135\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4679 - accuracy: 0.8581 - val_loss: 0.7328 - val_accuracy: 0.8190\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4552 - accuracy: 0.8608 - val_loss: 0.7294 - val_accuracy: 0.8185\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4664 - accuracy: 0.8583 - val_loss: 0.7304 - val_accuracy: 0.8160\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4644 - accuracy: 0.8599 - val_loss: 0.7265 - val_accuracy: 0.8162\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 77s 99ms/step - loss: 0.4601 - accuracy: 0.8591 - val_loss: 0.7368 - val_accuracy: 0.8146\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 78s 99ms/step - loss: 0.4562 - accuracy: 0.8589 - val_loss: 0.7258 - val_accuracy: 0.8153\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}